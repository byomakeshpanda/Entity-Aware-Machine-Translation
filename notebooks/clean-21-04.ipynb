{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43de601b-9879-4a70-8792-6bd51f7ea6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset, Dataset\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463731e5-27a1-4886-8d40-863cda72db64",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a6ec45-09cf-49ab-8fd6-978d2c88d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_train(data_path,only_eamt=False):\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    formatted_data = []\n",
    "    for sample in data:\n",
    "        source_text = sample[\"source\"]\n",
    "        target_text = sample[\"target\"]\n",
    "        entities = sample.get(\"enriched_entities\", [])\n",
    "\n",
    "        entity_annotations = [f\"{ent['entity_name']['en']}\" for ent in entities]\n",
    "        entity_text = \", \".join(entity_annotations) if entity_annotations else \"None\"\n",
    "\n",
    "        if only_eamt != True:\n",
    "            formatted_data.append({\n",
    "                    \"task\": \"NER\",\n",
    "                    \"input\": f\"Recognize entities: {source_text}\",\n",
    "                    \"output\": entity_text\n",
    "                })\n",
    "        formatted_data.append({\n",
    "            \"task\": \"Entity-aware MT\",\n",
    "            \"input\": f\"Entity translate (EN→FR): {source_text}\",\n",
    "            \"output\": target_text\n",
    "        })\n",
    "    return Dataset.from_list(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb2d642-71c7-446b-9e70-643a6d32852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_test(data_path):\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    formatted_data = []\n",
    "    for sample in data:\n",
    "        source_text = sample[\"source\"]\n",
    "        target_text = sample[\"target\"]\n",
    "        formatted_data.append({\n",
    "            \"task\": \"Entity-aware MT\",\n",
    "            \"input\": f\"Entity translate (EN→FR): {source_text}\",\n",
    "            \"output\": target_text\n",
    "        })\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d3ade3-6c4a-4959-848a-3f916cb69d4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many states touch Lake Michigan?',\n",
       "  'output': 'Combien d’États touchent le lac Michigan ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has a larger population, Canada or China?',\n",
       "  'output': 'Quel est le pays le plus peuplé, le Canada ou la Chine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who directed the movie that is based on the second book of The Lord of the Rings series?',\n",
       "  'output': 'Qui a réalisé le film inspiré du deuxième livre de la série Le Seigneur des anneaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country did not ratify the Treaty of Versailles?',\n",
       "  'output': 'Quel pays n’a pas ratifié le traité de Versailles ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who wrote Neuromancer?',\n",
       "  'output': 'Qui a écrit le livre Neuromancien ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did the author who wrote the Baby-Sitters Club books graduate from Smith College?',\n",
       "  'output': 'Quand l’auteure des livres Le Club des Baby-Sitters a-t-elle été diplômée du Smith College ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the distributor of the upcoming TV series based upon the Tolkien Middle Earth books?',\n",
       "  'output': 'Qui est le distributeur de la série télé à venir basée sur les livres de Tolkien de la série Terre du Milieu ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the last time Guillermo del Toro won an Academy Award for Best Director?',\n",
       "  'output': 'Quelle est la dernière fois que Guillermo del Toro a remporté un Oscar du meilleur réalisateur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which French leader was originally a Corsican nationalist and born on Aug 15, 1769?',\n",
       "  'output': 'Quel leader français était à l’origine nationaliste corse et était né le 15 août 1769 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What country has put the most people into space?',\n",
       "  'output': 'Quel pays a envoyé le plus de personnes dans l’espace ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country got independence first in Africa?',\n",
       "  'output': 'Quel est le premier pays à avoir obtenu l’indépendance en Afrique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did the album 19 by Adele win the Mercury Music Prize in 2008?',\n",
       "  'output': 'L’album 19 d’Adèle a-t-il remporté le prix musical Mercury en 2008 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Beijing the capital of Italy?',\n",
       "  'output': 'La ville de Pékin est-elle la capitale de l’Italie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Germany attack Pearl Harbor on December 7, 1941?',\n",
       "  'output': 'L’Allemagne a-t-elle attaqué Pearl Harbor le 7 décembre 1941 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the leader of England when the United States bombed Japan?',\n",
       "  'output': 'Qui était le dirigeant d’Angleterre quand les États-Unis ont bombardé le Japon ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many books are in the Lord of the Rings?',\n",
       "  'output': 'Combien de livres compte Le Seigneur des anneaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was \"Super Smash Bros\" released?',\n",
       "  'output': 'Quand ’Super Smash Bros’ est-il sorti ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries have over 500 million people?',\n",
       "  'output': 'Combien de pays possèdent une population de plus de 500 millions d’habitants ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first woman vice president of the United States?',\n",
       "  'output': 'Qui est la première vice-présidente des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is president of Peru?',\n",
       "  'output': 'Qui est le Président du Pérou ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the German dictator that started World War II and was married to Eva Braun shortly before their death?',\n",
       "  'output': 'Quel est le dictateur allemand ayant déclenché la Seconde Guerre mondiale qui était marié à Eva Braun peu avant leur mort ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What kind of legislature does Colombia have?',\n",
       "  'output': 'De quel type de législature la Colombie dispose-t-elle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the leader of the country that was the source of Covid-19?',\n",
       "  'output': 'Qui est le dirigeant du pays dans lequel la Covid-19 est apparu ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What city is the capital of California?',\n",
       "  'output': 'Quelle ville est la capitale de la Californie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Diary of a Wimpy Kid books are there?',\n",
       "  'output': 'Combien de tomes compte la série littéraire Journal d’un dégonflé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which governor spent the longest total amount of time in Office?',\n",
       "  'output': 'Quel gouverneur a passé le plus de temps en fonction ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What month was it when the third U.S. president left office?',\n",
       "  'output': 'En quel mois le troisième président des États-Unis a quitté ses fonctions ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Virginia governors have not been Democrat since 2000?',\n",
       "  'output': 'Quels gouverneurs de Virginie n’ont pas été démocrates depuis 2000 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Boris Yeltsin die in office as president of Russia?',\n",
       "  'output': 'Boris Eltsine est-il mort pendant son mandat de président de la Russie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the father of the only female prime minister in India?',\n",
       "  'output': 'Qui était le père de la seule femme Première ministre d’Inde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Gone with the Wind written by Margaret Mitchell?',\n",
       "  'output': 'Autant en emporte le vent a-t-il été écrit par Margaret Mitchell ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which is the windiest city in the world and is located on an island?',\n",
       "  'output': 'Quelle est la ville la plus ventée du monde et qui est située sur une île ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the First Lady of the first divorced US president?',\n",
       "  'output': 'Qui était la Première dame du premier président américain divorcé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did J. D. Salinger die?',\n",
       "  'output': 'Quand est mort J.D. Salinger ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Abraham Lincoln the 2nd president of the US?',\n",
       "  'output': 'Abraham Lincoln était-il le deuxième président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was president during World War One?',\n",
       "  'output': 'Qui était Président pendant la Première Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first prime minister of Japan?',\n",
       "  'output': 'Qui a été le premier ministre du Japon ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many wives did King Henry IV have?',\n",
       "  'output': 'Combien de femmes avait le roi Henri IV ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How many of Robert Caro's books won a Pulitzer Prize?\",\n",
       "  'output': 'Combien de livres de Robert Caro ont remporté un Prix Pulitzer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the last Ptolemaic ruler of Egypt?',\n",
       "  'output': 'Qui était le dernier dirigeant ptolémaïque d’Égypte ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was prime minister of Great Britain during the Falklands War and also a close personal friend of American President Ronald Reagan?',\n",
       "  'output': 'Qui était le Premier ministre de Grande Bretagne pendant la guerre des Malouines et aussi l’ami personnel du président Américain, Ronald Reagan ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Despicable Me movies are there?',\n",
       "  'output': 'Combien de films compte la saga Moi, moche et méchant ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the last year the Chicago cubs won the World Series?',\n",
       "  'output': 'En quelle année les Cubs de Chicago ont-ils remporté la Série mondiale pour la dernière fois ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What actress played Marty's girlfriend in the first Back to the Future movie but not the second?\",\n",
       "  'output': 'Quelle actrice a joué la petite amie de Marty dans le premier film Retour vers le futur mais pas dans le second ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Has a president of the U.S. ever been impeached?',\n",
       "  'output': 'Un président des États-Unis a-t-il jamais été destitué ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What country in Latin America has a lower GDP, Guatemala or Peru?',\n",
       "  'output': 'Quel pays d’Amérique latine a le plus faible PIB, le Guatemala ou le Pérou ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does Fifty Shades of Grey have more books than Harry Potter?',\n",
       "  'output': 'Est-ce que Cinquante Nuances de Grey a plus de livres que Harry Potter ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did Ramses II rule?',\n",
       "  'output': 'Sur quelle période s’étend le règne de Ramsès II ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the second largest ice mass on the earth?',\n",
       "  'output': 'Quelle est la deuxième plus grande masse de glace sur Terre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the character in the Great Gatsby originally from North Dakota and was very wealthy?',\n",
       "  'output': 'Qui était le personnage de Gatsby le Magnifique originaire du Dakota du Nord et qui était très riche ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was the first Newbery Medal recipient when he died?',\n",
       "  'output': 'À quel âge est décédé le premier lauréat de la Médaille Newbery ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was X-COM: Terror from the Deep released before X-COM: Interceptor?',\n",
       "  'output': 'X-COM : Terror from the Deep est-il sorti avant X-COM : Interceptor ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which actor not born in the United States starred as Spider-Man?',\n",
       "  'output': 'Quel acteur n’étant pas né aux États-Unis a joué Spiderman ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third Lord of The Rings movie?',\n",
       "  'output': 'Quel est le troisième film de la série Le Seigneur des anneaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did the Jazz Messengers start?',\n",
       "  'output': 'Quand les Jazz Messengers ont-ils commencé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the first book in the Wheel of Time series?',\n",
       "  'output': 'Quel est le titre du premier livre de la série La roue du temps ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the current wife of the current prime minister of the United Kingdom?',\n",
       "  'output': 'Qui est l’épouse actuelle de l’actuel Premier ministre du Royaume-Uni ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Academy Awards has Russell Crowe won?',\n",
       "  'output': 'Combien d’Oscars Russel Crowe a-t-il remporté ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Rashida Ellis win a medal at the 2021 Olympics?',\n",
       "  'output': 'Rashida Ellis a-t-elle remporté une médaille aux Jeux Olympiques de 2021 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which game was released first, Assassin's Creed IV: Black Flag or Assassin's Creed Syndicate?\",\n",
       "  'output': 'Quel jeu est sorti en premier, Assassin’s Creed IV : Black Flag ou Assassin’s Creed Syndicate ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which of the three largest islands in the Mediterranean Sea is not part of Italy?',\n",
       "  'output': 'Laquelle des trois plus grandes îles de la mer Méditerranée ne fait pas partie de l’Italie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries were Principal Allied Powers in Allies of World War I?',\n",
       "  'output': 'Combien de pays formaient les principales puissances alliées de la Première Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Lake Tanganyika deeper than Lake Nyasa?',\n",
       "  'output': 'Le lac Tanganyika est-il plus profond que le lac Nyasa ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): For what movie did Tom Hanks get his first Oscar nomination for Best Actor?',\n",
       "  'output': 'Pour quel film Tom Hanks a-t-il décroché sa première nomination à l’Oscar du meilleur acteur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first husband of Livia and the biological father of the second Roman Emperor Tiberius?',\n",
       "  'output': 'Qui était le premier mari de Livie et le père biologique de Tiberius, deuxième empereur romain ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What caused ancient Rome to fall?',\n",
       "  'output': 'Qu’est-ce qui a causé la chute de la Rome antique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the second longest river in Africa?',\n",
       "  'output': 'Quel est le deuxième plus long fleuve d’Afrique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which city is the capital of Mexico?',\n",
       "  'output': 'Quelle ville est la capitale du Mexique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who has served on the US Supreme Court the longer, Sonia Sotomayor or Elena Kagan?',\n",
       "  'output': 'Entre Elena Kagan et Sonia Sotomayor, qui a fait plus de temps à la tête de la Cour suprême des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the leader of the country that invaded Finland during the Winter War?',\n",
       "  'output': 'Qui était le dirigeant du pays qui a envahi la Finlande pendant la guerre d’Hiver ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many books are in the Fifty Shades of Grey series?',\n",
       "  'output': 'Combien de livres figurent dans la série Cinquante Nuances de Grey ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which mountain is taller, Everest or Mount St. Helens?',\n",
       "  'output': 'Quelle montagne est la plus haute, l’Everest ou le mont Saint Helens ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What date was the actress born who played Scarlett in \"Gone with the Wind\"?',\n",
       "  'output': 'Quelle est la date de naissance de l’actrice qui a joué le rôle de Scarlett dans Autant en emporte le vent ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What ancient civilization invented paper?',\n",
       "  'output': 'Quelle civilisation antique a inventé le papier ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which lasted longer, the American Revolutionary War or the Civil War?',\n",
       "  'output': 'Laquelle a duré plus longtemps : la guerre d’indépendance des États-Unis ou la sécession ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Charles Darwin win a Pulitzer prize?',\n",
       "  'output': 'Charles Darwin a-t-il remporté un prix Pulitzer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the capital of the country with the largest land size?',\n",
       "  'output': 'Quelle est la capitale du pays qui a la plus vaste étendue terrestre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which game in the Fatal Frame series did not get released in North America?',\n",
       "  'output': 'Quel est le jeu de la série Fatal Frame qui n’a pas été rendu disponible en Amérique du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which solo writer wrote the most amount of books in the New Jedi Order series?',\n",
       "  'output': 'Quel écrivain a écrit en solo le plus grand nombre de tomes de la série Le Nouvel Ordre Jedi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which South American countries does Brazil not share a border with?',\n",
       "  'output': 'Avec quels pays sud-américains le Brésil ne partage-t-il pas de frontière ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Stockholm the capital of Denmark?',\n",
       "  'output': 'Stockholm est-elle la capitale du Danemark ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first king of Norway?',\n",
       "  'output': 'Qui était le premier roi de Norvège ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the white tower of the Tower of London built?',\n",
       "  'output': 'Quand la Tour Blanche de la Tour de Londres a-t-elle été construite ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many wives did Ramesses II have?',\n",
       "  'output': 'Combien de femmes a eu Ramsès II ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who was a member of the 2021 U.S. men's national basketball team and was born in Grand Rapids, Michigan?\",\n",
       "  'output': 'Quel membre de l’équipe nationale masculine de basketball des États-Unis de 2021 est né à Grand Rapids, dans le Michigan ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was president of the United States during WWI?',\n",
       "  'output': 'Qui était président des États-Unis pendant la Première Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Where was Los Angeles Angels' two-way star born?\",\n",
       "  'output': 'Où est né le meilleur joueur bidirectionnel des Angels de Los Angeles ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many US House of Representative seats does Delaware have?',\n",
       "  'output': 'Combien de sièges à la Chambre des représentants des États-Unis le Delaware compte-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Timothy Zahn write a book in the New Jedi Order series?',\n",
       "  'output': 'Timothy Zahn a-t-il écrit un livre dans la série Le Nouvel Ordre Jedi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which three people are tied for the most Grand Slam titles in men's tennis?\",\n",
       "  'output': 'Quelles sont les 3 personnes qui détiennent le plus grand nombre de titres du Grand Chelem du tennis masculin ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the deepest river in the U.S.?',\n",
       "  'output': 'Quel est le fleuve le plus profond des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third longest river in Africa?',\n",
       "  'output': 'Quel est la troisième plus longue rivière d’Afrique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): In what year was Edgar Allen Poe's poem The Raven published?\",\n",
       "  'output': 'En quelle année a été publié le poème Le Corbeau d’Edgar Allan Poe ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What president was instrumental in building the Panama Canal?',\n",
       "  'output': 'Quel président a été déterminant pour la construction du canal de Panama ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the first Stuff Pack for The Sims 4?',\n",
       "  'output': 'Quel était le premier Stuff Pack sur Les Sims 4 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Where was The Beatles' first US performance?\",\n",
       "  'output': 'Où est-ce les Beatles ont présenté leur premier spectacle aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the original drummer in Mötley Crüe?',\n",
       "  'output': 'Qui était le batteur d’origine de Motley Crüe ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many US senators are there?',\n",
       "  'output': 'Combien y a-t-il de sénateurs aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Africa the continent with the most countries?',\n",
       "  'output': 'L’Afrique est-elle le continent qui compte le plus de pays ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What United States president was the tallest and the first to have a full beard?',\n",
       "  'output': 'Quel président des États-Unis a été le plus grand et le premier à porter la barbe ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was George Clooney ever in the movie From Dust Til Dawn?',\n",
       "  'output': 'George Clooney a-t-il déjà joué dans Une nuit en enfer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What river flows through the entirety of Egypt and is also the longest river in the world?',\n",
       "  'output': 'Quel est le fleuve qui traverse toute l’Égypte et qui est aussi le plus long fleuve du monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country in South America has the longest coastline?',\n",
       "  'output': 'Quel pays d’Amérique du Sud possède la plus longue rive ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Zidane Tribal the main character in Final Fantasy IX?',\n",
       "  'output': 'Djidane Tribal est-il le personnage principal de Final Fantasy IX ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which city is nicknamed Sin City?',\n",
       "  'output': 'Quelle ville est surnommée la Ville du pêché ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the 7th president of the United States?',\n",
       "  'output': 'Qui était le 7e Président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what year was the first moon landing?',\n",
       "  'output': 'En quel année s’est produit le premier alunissage ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Mount Saint Helens in Oregon?',\n",
       "  'output': 'Le Mont Saint Helens se trouve-t-il à Oregon ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was California governor and was also a movie actor?',\n",
       "  'output': 'Qui a été gouverneur de Californie et a également été acteur de cinéma ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who designed Mount Rushmore?',\n",
       "  'output': 'Qui a conçu le mont Rushmore ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the nickname for New Orléans?',\n",
       "  'output': 'Quel est le surnom de La Nouvelle-Orléans ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What video has been downloaded the most?',\n",
       "  'output': 'Quelle vidéo a été la plus téléchargée ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the president during the Spanish-American War who was assassinated during office?',\n",
       "  'output': 'Qui était le président pendant la guerre hispano-américaine, assassiné en exercice ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What city never sleeps?',\n",
       "  'output': 'Quelle ville ne dort jamais ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Was Enid Blyton a British children's author?\",\n",
       "  'output': 'Enid Blyton était-elle une auteure britannique de livres pour enfants ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Has Mount St. Helens erupted after 1970?',\n",
       "  'output': 'Le mont Saint Helens est-il entré en éruption après 1970 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Crime and Punishment come out before 1852?',\n",
       "  'output': 'Crime et Châtiment est-il sorti avant 1852 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was president of the United States and Chief Justice of the Supreme Court?',\n",
       "  'output': 'Qui a été président des États-Unis et président de la Cour Suprême ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which wife of Henry VIII did not die before him?',\n",
       "  'output': 'Quelle femme d’Henri VIII n’est pas décédée avant lui ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the Aztec Empire formed?',\n",
       "  'output': 'Quand a été formé l’Empire aztèque ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which game in the Assassin's Creed series has sold the most copies?\",\n",
       "  'output': 'Quel est le jeu de la série Assassins Creed qui a été le plus vendu ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What actor played James Bond and was born in Scotland?',\n",
       "  'output': 'Quel acteur né en Écosse a joué le rôle de James Bond ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which of the top 3 highest mountains in the world is not located in China?',\n",
       "  'output': 'Laquelle des 3 plus hautes montagnes du monde n’est pas située en Chine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which book is longer, The Fellowship of the Ring or The Two Towers?',\n",
       "  'output': 'Quel livre est plus long : La Communauté de l’Anneau ou Les Deux Tours ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the last time the San Francisco Giants won the World Series?',\n",
       "  'output': 'Quand les Giants de San Francisco ont-ils remporté la série mondiale pour la dernière fois ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the third president of India?',\n",
       "  'output': 'Qui était le troisième Président d’Inde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which capital cities of a country are not above sea level?',\n",
       "  'output': 'Quelles capitales sont situées au-dessous du niveau de la mer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which city is nicknamed The Magic City?',\n",
       "  'output': 'Quelle ville est surnommée la Ville magique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many novels did Ernest Hemingway publish before A Farewell to Arms?',\n",
       "  'output': 'Combien de romans Ernest Hemingway a-t-il publiés avant l’Adieu aux armes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many NBA players have been elected to the U.S. Senate?',\n",
       "  'output': 'Combien de joueurs de la NBA ont été élus au Sénat des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What river flows through both Austria and Romania?',\n",
       "  'output': 'Quel fleuve traverse à la fois l’Autriche et la Roumanie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What movie is directed by David Lowery and is about King Arthur?',\n",
       "  'output': 'Quel film est réalisé par David Lowery et porte sur le roi Authur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year was the Mongol Empire founded?',\n",
       "  'output': 'En quelle année s’est fondé l’Empire mongol ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is Alicia Key's 5th album called?\",\n",
       "  'output': 'Quel est le 5e album d’Alicia Key ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was to Kill a Mockingbird written in the 1980s?',\n",
       "  'output': 'Ne tirez pas sur l’oiseau moqueur a-t-il été écrit dans les années 80 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many planets are there in the Solar System?',\n",
       "  'output': 'Combien y a-t-il de planètes dans le système solaire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Christopher Columbus come to the Americas in 1492?',\n",
       "  'output': 'Christophe Colomb est-il venu aux Amériques en 1492 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries are completely surrounded by Italy?',\n",
       "  'output': 'Combien de pays sont complètement entourés par l’Italie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which actor played Terry Malloy in \"On the Waterfront\" and whose religion is Christian Scientist?',\n",
       "  'output': 'Quel est l’acteur qui a joué le rôle de Terry Malloy dans « Sur les quais » et dont la religion est la science chrétienne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the 20th president of the United States?',\n",
       "  'output': 'Qui était le 20e président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was assassinated on April 14, 1885 and was the 16th president of the United States?',\n",
       "  'output': 'Qui a été assassiné le 14 avril 1885 et a été le 16e président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which book is longer, The Lord of the Rings or Atlas Shrugged?',\n",
       "  'output': 'Quel livre est le plus long : Le Seigneur des anneaux ou La Révolte d’Atlas ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who killed MLK junior?',\n",
       "  'output': 'Qui a tué Martin Luther King ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which book in the A Song of Ice and Fire series was written in the same year as the last Atlanta Olympics?',\n",
       "  'output': 'Quel livre de la série Le Trône de fer a été écrit la même année que les derniers Jeux olympiques d’Atlanta ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what year was the spitball banned?',\n",
       "  'output': 'En quelle année la balle mouillée a-t-elle été interdite ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who's the king of Thailand?\",\n",
       "  'output': 'Qui est le roi de la Thaïlande ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Beyoncé album sold more copies, Homecoming: The Live Album or The Lion King: The Gift?',\n",
       "  'output': 'Lequel de ces deux albums de Beyoncé s’est-il le plus vendu : « Homecoming: The Live Album » ou « The Lion King : The Gift » ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the smallest country that is part of the largest continent?',\n",
       "  'output': 'Quel est le plus petit pays qui fait partie du plus grand continent ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which team won the latest World Series?',\n",
       "  'output': 'Quelle équipe a remporté la dernière Série mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Louisa May Alcott the author of Northanger Abbey?',\n",
       "  'output': 'Louisa May Alcott est-elle l’auteure de L’Abbaye de Northanger ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did 5 Seconds of Summer form?',\n",
       "  'output': 'Quand le groupe Five Seconds of Summer s’est-il formé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Olympic medals does Kerri Walsh Jennings have?',\n",
       "  'output': 'Combien de médailles Olympiques Kerri Walsh Jennings a-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Bobby Wagner still with the Seattle Seahawks?',\n",
       "  'output': 'Bobby Wagner joue-t-il encore avec les Seahawks de Seattle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many seas surround Japan?',\n",
       "  'output': 'Combien de mers entourent le Japon ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Call of Duty 4: Modern Warfare get released after Call of Duty: Black Ops?',\n",
       "  'output': 'Call of Duty 4 : Modern Warfare est sorti après Call of Duty : Black Ops ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): At what age did the son of King Philip II become the king of Macedonia?',\n",
       "  'output': 'À quel âge le fils du roi Philippe II est-il devenu roi de Macédoine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which continent does not have its own unique name, that is to say that no country shares its name, as well?',\n",
       "  'output': 'Quel continent ne porte pas de nom unique, c’est-à-dire qu’aucun pays ne partage pas, non plus, son nom ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which C.S. Lewis book was released earlier, The Four Loves or The Great Divorce?',\n",
       "  'output': 'Quel ouvrage de C.S. Lewis a été publié en premier, Les quatre amours ou Le Grand Divorce entre le ciel et la terre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the most expensive song to license?',\n",
       "  'output': 'Quelle chanson a le permis de reproduction le plus cher ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has sent more people into space, the United States or Russia?',\n",
       "  'output': 'Quel pays a envoyé plus de gens dans l’espace, les États-Unis ou la Russie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Grammy Award was Dirty Computer by Janelle Monáe nominated for but did not win?',\n",
       "  'output': 'Pour quel Grammy Award Dirty Computer de Janelle Monae a-t-il été nominé sans pour autant gagner le prix ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Where was the highest ever recorded temperature in history?',\n",
       "  'output': 'Où a eu lieu la température la plus élevée jamais enregistrée dans l’histoire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest country in Africa by population?',\n",
       "  'output': 'Quel est le pays le plus peuplé d’Afrique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which movie had a bigger budget, The Wizard of Oz or Gone With The Wind?',\n",
       "  'output': 'Quel film a eu un plus gros budget : Le Magicien d’Oz ou Autant en emporte le vent ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In Animal Crossing: New Horizons, who is the father of the twins who run the general store?',\n",
       "  'output': 'Dans Animal Crossing : New Horizons, qui est le père des jumeaux qui dirigent le General store ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many copies of Harry Potter and the Order of the Phoenix sold in its first 24 hours?',\n",
       "  'output': 'Combien d’exemplaires de Harry Potter et l’Ordre du Phénix ont été vendus dans les vingt-quatre premières heures ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What are the major political parties of the United States?',\n",
       "  'output': 'Quels sont les principaux partis politiques des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which of Columbus's ships did not make it back to Spain?\",\n",
       "  'output': 'Quels navires de Colomb ne sont pas parvenus à rentrer en Espagne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In which state did the first flight occur and contains part of the Great Smokey Mountains national park?',\n",
       "  'output': 'Dans quel État s’est produit le premier vol et qui contient une partie du parc national des Monts Great Smoky ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which war was longer, the Civil War or the Revolutionary War?',\n",
       "  'output': 'Quelle guerre était la plus longue : la guerre de sécession ou la guerre d’indépendance ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the third NBA team Shaquille O'Neal played for?\",\n",
       "  'output': 'Quelle est la troisième équipe de NBA pour laquelle Shaquille O’Neal a joué ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was a wife of King Henry VIII and the cousin of Anne Boleyn?',\n",
       "  'output': 'Quelle épouse du roi Henri VIII était la cousine d’Anne Boleyn ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Naples the capital of Italy?',\n",
       "  'output': 'Naples est-elle la capitale de l’Italie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the youngest person to win a UEFA Champions League Cup?',\n",
       "  'output': 'Qui est la plus jeune personne à avoir remporté une coupe de ligue des champions de l’UEFA ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest country of Africa in population?',\n",
       "  'output': 'Quel est le pays le plus peuplé d’Afrique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Star Wars: Knights of the Old Republic games were released on the original Xbox?',\n",
       "  'output': 'Combien de jeux Star Wars : Knights of the Old Republic sont sortis sur la Xbox originale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did the New York Jets win a Super Bowl?',\n",
       "  'output': 'Les Jets de New York ont-il remporté un Super Bowl ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What country hosted the second ever Winter Olympics?',\n",
       "  'output': 'Quel pays a accueilli les deuxièmes Jeux olympiques d’hiver de l’histoire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which major war did the US not win?',\n",
       "  'output': 'Quelle guerre majeure les États Unis n’ont-ils pas gagnée ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest lake in miles squared in the United Kingdom?',\n",
       "  'output': 'Quel est le plus grand lac en milles carrés du Royaume-Uni ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which song was nominated for MTV VMA Best Video of the Year and did not win in 2021?',\n",
       "  'output': 'Sous quel titre se présente le tube qui a été nominé pour le MTV Video Music Award de la vidéo de l’année, mais n’a pas été récompensé en 2021 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did the author who wrote Lord Of The Flies die?',\n",
       "  'output': 'Quand est né l’auteur de Sa Majesté des mouches ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the nationality of the latest Pulitzer prize winner?',\n",
       "  'output': 'Quelle est la nationalité du dernier lauréat du prix Pulitzer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Academy Awards for Best Actor has Daniel Day-Lewis won?',\n",
       "  'output': 'Combien d’Oscars du meilleur acteur Daniel Day-Lewis a-t-il remporté ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which mountain is part of the Alps and is the tallest in Austria?',\n",
       "  'output': 'Quelle montagne fait partie des Alpes et est le sommet le plus élevé d’Autriche ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which book was published in 1985 and won a Nebula Award for Best Novel?',\n",
       "  'output': 'Quel livre a été publié en 1985 et a remporté le prix Nebula du meilleur roman ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the director of Field of Dreams born?',\n",
       "  'output': 'Quelle est la date de naissance du réalisateur du film Jusqu’au bout du rêve ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year were the Houston Texans founded?',\n",
       "  'output': 'En quelle année ont été fondés les Texans de Houston ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was not a member of the Allied Powers during World War II?',\n",
       "  'output': 'Quel pays n’était pas membre des puissances alliées pendant la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many rivers in the world are longer than the Mississippi River?',\n",
       "  'output': 'Combien de fleuves dans le monde sont plus longs que le fleuve Mississippi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Dwayne Johnson in the movie Moana?',\n",
       "  'output': 'Dwayne Johnson a-t-il joué dans Vaiana : La Légende du bout du monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the wife of the president during the majority of World War II?',\n",
       "  'output': 'Qui était la femme du Président en exercice pendant la majeure partie de la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which city contains the University of Pennsylvania?',\n",
       "  'output': 'Dans quelle ville se trouve l’Université de Pennsylvanie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which books were nominated for the 2020 Nebula Award for Best Novel, but did not win?',\n",
       "  'output': 'Quels livres ont été nominés pour le Prix Nebula du meilleur roman en 2020, mais ne l’ont pas remporté ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries in Africa?',\n",
       "  'output': 'Combien de pays se situent en Afrique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many states have never had a female governor?',\n",
       "  'output': 'Combien d’États n’ont jamais eu une femme au poste de gouverneur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many principal areas of Wales have a population of less than 90,000?',\n",
       "  'output': 'Combien de territoires principaux du Pays de Galles ont une population inférieure à 90 000 habitants ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Herman Melville novel features a character called Ahab?',\n",
       "  'output': 'Quel roman de Herman Meville met en scène un personnage du nom de Ahab ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which member of Blackpink was not allowed to join Paris Fashion Week in 2021?',\n",
       "  'output': 'Quels membres de Blackpink n’avait pas été admis à la Semaine de la mode de Paris en 2021 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What party did the U.S. president belong during the attack to the twin towers?',\n",
       "  'output': 'A quel parti appartenait le président des États-Unis en exercice lors de l’attaque des tours jumelles ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many wives did King Solomon have?',\n",
       "  'output': 'Combien de femmes avait le roi Salomon ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest city in India by population according to the UN 2018 population estimates?',\n",
       "  'output': 'Quelle est la ville la plus peuplée d’Inde selon les statistiques démographiques de l’ONU en 2018 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Parasite win the Oscar for Best Picture?',\n",
       "  'output': 'Parasite a-t-il remporté l’Oscar du meilleur film ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the narrator for the English language version of the movie March of the Penguins?',\n",
       "  'output': 'Qui était le narrateur de la version anglaise du film La Marche de l’empereur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Sacramento the capital of California?',\n",
       "  'output': 'Sacramento est-elle la capitale de la Californie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the first largest earthquake ever recorded?',\n",
       "  'output': 'Quel a été le premier plus grand séisme jamais enregistré ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Academy Awards has Jessica Chastain won?',\n",
       "  'output': 'Combien d’Oscars du cinéma Jessica Chastain a-t-elle remportés ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the deepest point on Earth?',\n",
       "  'output': 'Quel est le point le plus profond sur Terre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which states in the U.S. are not connected with the other states in USA?',\n",
       "  'output': 'Quels États des États-Unis ne sont pas reliés aux autres États des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what city would you find the C.N.Tower?',\n",
       "  'output': 'Dans quelle ville trouve-t-on la Tour CN ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Titanic win Best Picture?',\n",
       "  'output': 'Titanis a-t-il remporté l’Oscar de la meilleur photographie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the prime minister of Israel?',\n",
       "  'output': 'Qui est le Premier ministre d’Israël ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Star Wars Original Trilogy movies were not directed by George Lucas?',\n",
       "  'output': 'Quels films de la première trilogie de Star Wars n’ont pas été réalisés par George Lucas ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many presidents has the US had?',\n",
       "  'output': 'Combien de présidents ont eu les États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which American states are entirely not connected to the continental landmass of North America?',\n",
       "  'output': 'Quels États américains ne sont absolument pas reliés à la masse continentale de l’Amérique du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state has more Congressional districts, California or Texas?',\n",
       "  'output': 'Quel État compte le plus de circonscriptions électorales, la Californie ou le Texas ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the member of One Direction who is Middle Eastern?',\n",
       "  'output': 'Qui était le membre des One Direction qui est originaire du Moyen-Orient ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what year did World War II end?',\n",
       "  'output': 'En quelle année s’est terminée la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many named oceans are there in the world?',\n",
       "  'output': 'Combien d’océans nommés y a-t-il dans le monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many wives did Roman Emperor Tiberius have?',\n",
       "  'output': 'Combien de femmes l’Empereur romain Tibère avait-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many teams does the NFC east have?',\n",
       "  'output': 'Combien d’équipes sont-elles membres de la NFC Est ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state did not send delegates to the Convention at Philadelphia?',\n",
       "  'output': 'Quel état n’a pas envoyé de délégués à la Convention de Philadelphie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the longest reigning emperor of Japan?',\n",
       "  'output': 'Qui était l’empereur du Japon qui a eu le règne le plus long ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Steven Spielberg direct Back to the Future?',\n",
       "  'output': 'Steven Spielberg a-t-il réalisé le film Retour vers le futur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year did the American Revolutionary War stop?',\n",
       "  'output': 'En quelle année s’est terminée la Guerre d’indépendance des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Great Lakes?',\n",
       "  'output': 'Combien y a-t-il de Grands Lacs ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the name of the little girl that the android, who rebels against Todd Williams, wants to protect in Detroit: Become Human?',\n",
       "  'output': 'Quel est le nom de la petite fille que l’androïde, qui se rebelle contre Todd Williams, veut protéger dans Detroit : Become Human ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which U.S. states do not share a border with any other part of the U.S.?',\n",
       "  'output': 'Quels États américains n’ont pas de frontière commune avec une autre partie des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the oldest to win an Oscar for Best Director?',\n",
       "  'output': 'Qui est la personne la plus âgée a avoir remporté un Oscar du meilleur réalisateur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which of the Goosebumps books released in 1992, does not have 132 pages?',\n",
       "  'output': 'Quel livre de la série Chair de poule publié en 1992, ne comporte pas 132 pages ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who was Hawaii's longest serving senator?\",\n",
       "  'output': 'Quel est le sénateur d’Hawaï ayant eu le plus long mandat ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many continents were discovered on Earth?',\n",
       "  'output': 'Combien de continents ont été découverts sur Terre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state has more electoral votes, Texas or California?',\n",
       "  'output': 'Quel État a le plus de votes électoraux, le Texas ou la Californie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the last Edo period shogun in Japan?',\n",
       "  'output': 'Qui était le dernier shogun à l’époque d’Édo au Japon ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What was Missy Elliot's first studio album?\",\n",
       "  'output': 'Quel était le premier album studio de Missy Elliot ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third largest of the Great Lakes by volume?',\n",
       "  'output': 'Quel est le troisième plus grand des Grands Lacs en termes de volume ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Hawaii the smallest US state by size?',\n",
       "  'output': 'Hawaï est-il le plus petit État américain en termes de superficie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the oldest person to win the Grammy Award for Song of the Year?',\n",
       "  'output': 'Qui est la personne la plus âgée à avoir remporté le Grammy Award de la chanson de l’année ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries participated in the 1896 Olympic Games in Athens?',\n",
       "  'output': 'Combien de pays ont participé aux Jeux olympiques de 1896 à Athènes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which mountain in the USA does not have an elevation below 20,000 feet?',\n",
       "  'output': 'Quelle montagne aux États-Unis n’a pas une hauteur inférieure à 20 000 pieds ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who belonged to the Democratic Party and was vice president as a woman?',\n",
       "  'output': 'Qui a appartenu au parti démocrate et a été vice-présidente ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many children does the lead actress in The Hunger Games have?',\n",
       "  'output': 'Combien d’enfants l’actrice principale de Hunger Games a-t-elle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who won the presidential elections in 2010 and 2012?',\n",
       "  'output': 'Qui a remporté les élections présidentielles en 2010 et en 2012 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the second book in the Ender's Shadow series?\",\n",
       "  'output': 'Quel est le deuxième livre de la série La Stratégie de l’ombre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the oldest president to be sworn into presidency for the USA?',\n",
       "  'output': 'Qui est le président le plus âgé à avoir prêté serment à la présidence des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the leader of the North American country that co-led an alliance to combat the Axis powers during World War II?',\n",
       "  'output': 'Qui était le dirigeant du pays nord-américain qui a co-dirigé une Alliance pour combattre les puissances de l’Axe pendant la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has a larger population, Bangladesh or Brazil?',\n",
       "  'output': 'Quel pays est le plus peuplé, le Bangladesh ou le Brésil ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How long is a term in the House of Representatives?',\n",
       "  'output': 'Quelle est la durée d’un mandat à la Chambre des Représentants ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which MLB team has won the most World Series titles?',\n",
       "  'output': 'Quelle équipe de la MLB a remporté le plus de titres de la Série mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many colonies did Great Britain have in America?',\n",
       "  'output': 'Combien de colonies la Grande-Bretagne avait-t-elle en Amérique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what year was the third president of the United States born?',\n",
       "  'output': 'En quelle année est né le 3e président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country was a part of the Allies Alliance in World War II and fought against the United States in the Cold War?',\n",
       "  'output': 'Quel pays faisait partie des forces Alliées pendant la 2e Guerre mondiale et s’est battu contre les États-Unis pendant la Guerre froide ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Wyoming the least densely populated state in the United States of America?',\n",
       "  'output': 'Wyoming est-il l’État le moins peuplé des États-Unis d’Amérique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Quito the capital of Ecuador?',\n",
       "  'output': 'Quito est-elle la capitale de l’Équateur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What river flows through Ecuador and is the largest river in South America?',\n",
       "  'output': 'Quel fleuve traverse l’Équateur tout en étant le plus grand fleuve d’Amérique du Sud ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is the vice president the first woman in that office?',\n",
       "  'output': 'La vice-présidente est-elle la première femme à occuper cette fonction ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Best Actor Oscars has Jack Nicholson won?',\n",
       "  'output': 'Combien d’Oscars du meilleur acteur Jack Nicholson a-t-il remportés ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which movie had a bigger budget, Gladiator or Troy?',\n",
       "  'output': 'Quel film avait le plus gros budget, Gladiator ou Troie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the longest serving U.S. president?',\n",
       "  'output': 'Qui a exercé le plus long mandat de président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In which city is the Brandenburg Gate located?',\n",
       "  'output': 'Dans quelle ville se trouve la Porte de Brandebourg ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the capital of the least populous U.S. state?',\n",
       "  'output': 'Quelle est la capitale de l’État le moins peuplé des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many islands in the Caribbean are over 29,000 square miles?',\n",
       "  'output': 'Combien d’îles des Caraïbes ont une superficie supérieure à 29 000 milles carrés ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first queen of England?',\n",
       "  'output': 'Qui était la première Reine d’Angleterre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the second tallest volcano in the world?',\n",
       "  'output': 'Quel est le deuxième plus grand volcan du monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What mountain is the tallest in the United States and is in Alaska?',\n",
       "  'output': 'Quelle est la montagne la plus élevée aux États-Unis et qui se trouve en Alaska ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the last Jaws movie starring Roy Schneider?',\n",
       "  'output': 'Quel est le dernier film de la série de films Les dents de la mer dans lequel Roy Schneider a un rôle principal ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who has been the oldest vice president to step foot in the White House?',\n",
       "  'output': 'Qui a été le plus ancien vice-président à accéder à la Maison Blanche ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What city is the most populated in West Africa?',\n",
       "  'output': 'Quelle ville est la plus peuplée d’Afrique de l’Ouest ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third largest country in the world by land mass?',\n",
       "  'output': 'Quel est le troisième plus grand pays du monde en termes de superficie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was a coach of the Boston Celtics and born in Upper Marlboro, Maryland?',\n",
       "  'output': 'Qui était entraîneur des Celtics de Boston et est né à Upper Marlboro, dans le Maryland ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest building in the city known as the Second City and the Windy City?',\n",
       "  'output': 'Quel est le plus haut bâtiment de la ville connue comme la deuxième ville et la Ville des vents ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the highest mountain in Scotland?',\n",
       "  'output': 'Quelle est la plus haute montagne d’Écosse ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which song was not the first rock-n-roll song to hit number one in the charts?',\n",
       "  'output': 'Quelle chanson, qui n’était pas du style rock-n-roll a atteint la première place dans le hit-parade ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what state was the 1996 Caldecott Medal winner born?',\n",
       "  'output': 'Dans quel État le lauréat de la Médaille Caldecott 1996 est-il né ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third tallest mountain in North America?',\n",
       "  'output': 'Quelle est la troisième plus haute montagne d’Amérique du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what year was the Sony PlayStation released in the United States?',\n",
       "  'output': 'En quelle année est sortie la Playstation Sony aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest lake in Australia?',\n",
       "  'output': 'Quel est le plus grand lac d’Australie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Olympic Games were held in countries that do not exist anymore?',\n",
       "  'output': 'Combien de Jeux Olympiques ont été organisés dans des pays qui n’existent plus ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What civilization ruled modern day Mexico?',\n",
       "  'output': 'Quelle civilisation a dirigé le Mexique moderne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who scored the fastest goal in World Cup Soccer history?',\n",
       "  'output': 'Qui a marqué le but le plus rapide de l’histoire de la Coupe du monde de football ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which monarchs reign was the longest?',\n",
       "  'output': 'Quel monarque a régné le plus longtemps ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which lake is the largest in the U.S. and largest northernmost of the Great Lakes of North America?',\n",
       "  'output': 'Quel lac est le plus grand des États-Unis et le plus grand situé à l’extrême nord des Grands Lacs d’Amérique du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Terminator movies has Arnold Schwarzenegger been in?',\n",
       "  'output': 'Dans combien de films Terminator Arnold Schwarzanegger a-t-il joué ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who won the first Academy Award for Best Actor?',\n",
       "  'output': 'Qui a remporté le premier Oscar du meilleur acteur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year was the author who wrote the Lord of the Rings series born?',\n",
       "  'output': 'En quelle année est né l’auteur de la série Le Seigneur des anneaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which Great Lakes isn't the deepest?\",\n",
       "  'output': 'Quels Grands Lacs ne sont pas les plus profonds ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Has Maunaloa erupted after 1990?',\n",
       "  'output': 'Le Mauna Loa est-il entré en éruption après 1990 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the biggest city in India?',\n",
       "  'output': 'Quelle est la plus grande ville d’Inde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the second largest state in the United States and has Austin as its capital?',\n",
       "  'output': 'Quel est le deuxième plus grand État des États-Unis et a pour capitale Austin ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which American war had the most American casualties?',\n",
       "  'output': 'Quelle guerre américaine a fait le plus grand nombre de victimes américaines ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does the United Kingdom have a president?',\n",
       "  'output': 'Le Royaume-Uni a-t-il un Président ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which foreign language movie was the first to win Best Pictures?',\n",
       "  'output': 'Quel film en langue étrangère était le premier à remporter l’Oscar du meilleur film ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country is based in Africa and has the most pyramids?',\n",
       "  'output': 'Quel pays est basé en Afrique et possède le plus de pyramides ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What Motown singer tried out for the Detroit Lions in 1970?',\n",
       "  'output': 'Quel chanteur de Motown a tenté d’intégrer les Lions de Détroit en mille neuf cent soixante-dix ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What book from 2008 was not released until 12 years later due to an online leak?',\n",
       "  'output': 'Quel livre de 2008 n’a été publié que 12 ans plus tard en raison d’une fuite en ligne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the name of the mother of Canada's 23rd prime minister?\",\n",
       "  'output': 'Comment s’appelle la mère du 23e Premier ministre canadien ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the first state to join the U.S. after the original thirteen?',\n",
       "  'output': 'Quel a été le premier État à rejoindre les États-Unis après les treize États d’origine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which party did the U.S. president during the moon landing belong to?',\n",
       "  'output': 'À quel parti appartenait le président des États-Unis en exercice pendant l’alunissage ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which war lasted longer, Iraq War or Korean War?',\n",
       "  'output': 'Quelle guerre a duré le plus longtemps, le guerre d’Irak ou la guerre de Corée ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has a larger population, Ecuador or Uruguay?',\n",
       "  'output': 'Quel pays est le plus peuplé, l’Équateur ou l’Uruguay ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest mountain in Scotland?',\n",
       "  'output': 'Quelle est la plus haute montagne d’Écosse ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which war has had the most casualties, including civilians?',\n",
       "  'output': 'Quelle guerre a fait le plus de victimes y compris des civils ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country colonized India first, the United Kingdom or France?',\n",
       "  'output': 'Quel pays a colonisé l’Inde en premier, le Royaume Uni ou la France ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many named characters die in \"To Kill A Mocking Bird\"?',\n",
       "  'output': 'Combien de personnages nommés meurent dans le livre « Ne tirez pas sur l’oiseau moqueur » ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old is the quarterback of the New England Patriots?',\n",
       "  'output': 'Quel âge a le quart-arrière des Patriots de la Nouvelle-Angleterre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the last eruption of Mount Fuji?',\n",
       "  'output': 'Quand a eu lieu la dernière éruption du mont Fuji ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Where did the quarterback who won Super Bowls for New England and Tampa Bay go to college?',\n",
       "  'output': 'Où le quart-arrière qui a remporté des Super Bowls avec l’équipe de la Nouvelle-Angleterre et celle de Tampa Bay est-il allé à l’université ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the leader of the Khmer Rouge?',\n",
       "  'output': 'Qui était le leader des Khmers rouges ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What crime did Raskolnikov commit in Crime and Punishment?',\n",
       "  'output': 'Quel crime Raskolnikov a-t-il commis dans Crime et Châtiment ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the first book in Ann Rice's, The Vampire Chronicles series?\",\n",
       "  'output': 'Quel est le premier tome de la série Chroniques des vampires d’Ann Rice ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who are the main characters in Of Mice and Men?',\n",
       "  'output': 'Qui sont les personnages principaux dans Des souris et des hommes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state has more electoral votes, California or Utah?',\n",
       "  'output': 'Quel État a le plus de votes électoraux, la Californie ou l’Utah ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Where have the most meteorites been found in the world?',\n",
       "  'output': 'Où a-t-on trouvé le plus de météorites dans le monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who has the record for most strikeouts in a season?',\n",
       "  'output': 'Qui détient le record de retraits sur des prises en une saison ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Barcelona the capital of Spain?',\n",
       "  'output': 'Barcelone est-elle la capitale de l’Espagne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which of the 5 largest airports in the world, ranked by size, is not located in the United States?',\n",
       "  'output': 'Lequel des 5 plus grands aéroports du monde, classés par taille, n’est pas situé aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the 2nd largest desert in the world?',\n",
       "  'output': 'Quel est le 2e plus grand désert au monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which A Series of Unfortunate Events book is the longest?',\n",
       "  'output': 'Quel est le plus long livre de la série Les Désastreuses Aventures des orphelins Baudelaire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How many members were in the final lineup of Destiny's Child?\",\n",
       "  'output': 'Combien de membres comptait le dernier groupe Destiny’s Child ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which governor of Washington state since 1980 was not from the Democratic Party?',\n",
       "  'output': 'Quel gouverneur de l’État de Washington depuis 1980 n’était pas issu du parti démocrate ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which city is known as the City of Lights?',\n",
       "  'output': 'Quelle ville est connue sous le nom de Ville des lumières ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the capital of Latvia?',\n",
       "  'output': 'Quelle est la capitale de la Lettonie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which sea surrounds Greece and also borders Turkey?',\n",
       "  'output': 'Quelle mer entoure la Grèce et borde également la Turquie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What country is the smallest country in the world and home to the Leaning Tower of Pisa?',\n",
       "  'output': 'Quel pays est le plus petit du monde et abrite la Tour de Pise ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which war lasted longer, the Boer War or the Crimean War?',\n",
       "  'output': 'Quelle guerre a duré plus longtemps, la guerre des Boers ou la guerre de Crimée ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the estimated current population of the state where Mount Rushmore is located as of 2020?',\n",
       "  'output': 'Quelle est la population actuelle estimée de l’État où se trouve le Mont Rushmore en 2020 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which was built first, Hadrian's Wall or the Great Wall of China?\",\n",
       "  'output': 'Lequel a été construit en premier, le mur d’Hadrien ou la Grande Muraille de Chine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many horns does the national animal of Scotland have?',\n",
       "  'output': 'Combien de cornes possède l’animal national de l’Écosse ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What actor played Harry Potter and was born in London?',\n",
       "  'output': 'Quel acteur a interprété Harry Potter et est né à Londres ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Hall of Fame quarterback played for the University of Tennessee and the Indianapolis Colts?',\n",
       "  'output': 'Quel quaterback de Hall of Fame a joué pour l’Université du Tennessee et les Colts d’Indianapolis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which provinces in Canada do not have French as an official language?',\n",
       "  'output': 'Quel provinces du Canada n’ont pas le français comme langue officielle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the name of the second largest volcano in the world?',\n",
       "  'output': 'Comment s’appelle le deuxième plus grand volcan au monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which band originally recorded Don't Cry?\",\n",
       "  'output': 'À l’origine, quel groupe a enregistré Don’t Cry ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did the Baltimore Orioles win the 1983 World Series?',\n",
       "  'output': 'Les Orioles de Baltimore ont-ils gagné la Série mondiale (World Series) de 1983 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the 43 president of the US and part owner of the Texas rangers?',\n",
       "  'output': 'Qui était le 43e président des États-Unis et copropriétaire des Texas rangers ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Planet of the Apes set on Earth?',\n",
       "  'output': 'La planète des singes se déroule-t-elle sur Terre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which German leader invaded the Soviet Union, but did not conquer it?',\n",
       "  'output': 'Quel dirigeant allemand a envahi l’Union soviétique mais ne l’a pas conquise ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first woman to assume the office of governor?',\n",
       "  'output': 'Qui est la première femme à assumer la fonction de Gouverneur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state is the 10th largest by area and home to Mount Hood?',\n",
       "  'output': 'Quel est le 10e plus grand État en termes de superficie et celui où se trouve le Mont Hood ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the most expensive book ever sold?',\n",
       "  'output': 'Quel est le livre le plus cher jamais vendu ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did All Eyez On Me come out in the same year as It Was Written did?',\n",
       "  'output': 'All Eyes On Me est-il sorti la même année que It Was Written ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which fruit/vegetable is very popular in Italy, and is associated closely with its cooking but is not native to it?',\n",
       "  'output': 'Quel fruit ou légume est très populaire en Italie et est étroitement lié à la cuisine italienne mais n’est pas originaire de ce pays ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Yosemite National Park is located in which state in the US?',\n",
       "  'output': 'Dans quel État des États-Unis se trouve le Parc national de Yosemite ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the wife of the first president of the United States?',\n",
       "  'output': 'Qui était la femme du premier président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Colombia a democratic country?',\n",
       "  'output': 'La Colombie est-elle un pays démocratique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who had a longer reign, Mary Tudor or Marie Antoinette?',\n",
       "  'output': 'Qui a eu le règne le plus long : Marie Tudor ou Marie-Antoinette ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the second NBA team Shaquille O'Neal played for?\",\n",
       "  'output': 'Quelle est la deuxième équipe de NBA pour laquelle Shaquille O’Neal a joué ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many federated states in Brazil have a population density above 100 km2?',\n",
       "  'output': 'Combien d’États fédérés du Brésil ont une densité de population supérieure à 100 km2 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who lost the most soldiers during the American Civil War, the Union or the Confederacy?',\n",
       "  'output': 'Entre les États confédérés d’Amérique et l’Union, qui a perdu plus de soldats pendant la guerre de Sécession ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did Usain Bolt receive his last Olympic medal?',\n",
       "  'output': 'Quand Usain Bolt a-t-il remporté sa dernière médaille olympique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the shortest river in the United States?',\n",
       "  'output': 'Quel est le fleuve le plus court aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Godfather movie is the longest?',\n",
       "  'output': 'Quel est le plus long film de la saga Le Parrain ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was the sixteenth president of the United States when he was assassinated?',\n",
       "  'output': 'Quel âge avait le 16e président des États-Unis quand il a été assassiné ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many times have the Los Angeles Dodgers lost the World Series?',\n",
       "  'output': 'Combien de fois les Dodgers de Los Angeles ont-ils perdu dans la série mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who ran in the 2020 Democratic Primaries and graduated from Howard University?',\n",
       "  'output': 'Qui s’est présenté aux primaires démocrates de 2020 et est diplômé de l’université Howard ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which American suffragist never got married?',\n",
       "  'output': 'Quelle suffragette américaine ne s’est jamais mariée ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Winston Churchill serve as UK prime minister before World War 1?',\n",
       "  'output': 'Winston Churchill a-t-il été Premier Ministre du Royaume-Uni avant la Première Guerre Mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What US state was the 26th president of the United States born in?',\n",
       "  'output': 'Dans quel État d’Amérique est né le 26e président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is older, Clint Eastwood or Cuba Gooding Jr.?',\n",
       "  'output': 'Qui est le plus âgé entre Clint Eastwood et Cuba Gooding Jr ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what year did the United States enter WW II?',\n",
       "  'output': 'En quelle année les États-Unis sont-ils entrés dans la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Breton a playable race in The Elder Scrolls: Skyrim?',\n",
       "  'output': 'Est-ce que Breton est une course jouable dans The Elder Scrolls : Skyrim ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which state did not vote the incumbent's party into the governorship in 2020?\",\n",
       "  'output': 'Quel État n’a pas voté pour le parti du gouverneur en exercice en 2020 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which continents don't have any land in the Northern Hemisphere?\",\n",
       "  'output': 'Quels continents n’ont aucun territoire dans l’hémisphère nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the fifth highest mountain in the USA?',\n",
       "  'output': 'Quelle est la cinquième montagne la plus haute des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which book in the Hitchhiker's Guide to the Galaxy series was released in 1992?\",\n",
       "  'output': 'Quel livre de la série Le Guide du voyageur galactique a été publié en 1992 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Did Liam Neeson win an Oscar for Schindler's List?\",\n",
       "  'output': 'Liam Neeson a-t-il remporté un Oscar pour « La Liste de Schindler » ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the highest elected office in Germany?',\n",
       "  'output': 'Quelle est la fonction la plus haute d’Allemagne à être soumise aux élections ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest recorded temperature change in one place over a 24-hour period?',\n",
       "  'output': 'Quel est le plus grand changement de température enregistré en un seul endroit sur une période de 24 heures ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Denali taller than Mount Blackburn?',\n",
       "  'output': 'Le Denali est-il plus haut que le Mont Blackburn ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the full name of the Hobbit that accompanies Frodo in the Lord of the Rings?',\n",
       "  'output': 'Quel est le nom complet du hobbit qui accompagne Frodo dans Le Seigneur des anneaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Mexico part of South America?',\n",
       "  'output': 'Le Mexique fait-il partie de l’Amérique du Sud ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Are there any mountain ranges in the United States?',\n",
       "  'output': 'Y a-t-il des chaînes de montagnes aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the shortest surviving child of King Henry VIII?',\n",
       "  'output': 'Qui était l’enfant survivant le plus petit du roi Henry VIII ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which cofounding members were no longer part of the Destiny's Child lineup after 2000?\",\n",
       "  'output': 'Quels membres co-fondateurs du groupe Destiny’s Child ne faisaient plus partie du groupe en 2000 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many studio albums does Ariana Grande have?',\n",
       "  'output': 'Combien d’albums studio Ariane Grande a-t-elle mis sur le marché ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): This famous actor died in 1980 from mesothelioma, a rare cancer caused by asbestos exposure?',\n",
       "  'output': 'Quel célèbre acteur est mort en 1980 d’un mésothéliome, un cancer rare causé par une exposition à l’amiante ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old is the current coach of Los Angeles Lakers?',\n",
       "  'output': 'Quel âge a l’entraîneur actuel des Lakers de Los Angeles ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many islands make up Hawaii?',\n",
       "  'output': 'Hawaï comprend combien d’îles ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which princess of Thailand did not marry a Thai citizen?',\n",
       "  'output': 'Quelle princesse de Thaïlande n’a pas épousé un citoyen Thaïlandais ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Where was the director of the adaptation of Schindler's List born?\",\n",
       "  'output': 'Quelle est l’année de naissance du réalisateur de l’adaptation de La Liste de Schindler ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the second largest country in the world ranked by area?',\n",
       "  'output': 'Quel est le deuxième plus grand pays du monde en superficie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Dr. Dre win a Grammy for \"Let me ride\"?',\n",
       "  'output': 'Dr Dre a-t-il gagné un Grammy pour «Let me ride» ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many video games have more than 90,000,000 sales?',\n",
       "  'output': 'Combien de jeux vidéo ont dépassé les 90 000 000 de ventes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What was R. L. Stine's first published book?\",\n",
       "  'output': 'Quel a été le premier livre publié par R.L. Stine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the only person not elected as US president or vice president to serve as president?',\n",
       "  'output': 'Qui est la seule personne non élue à la présidence ou à la vice-présidence des États-Unis à avoir exercé la fonction de président ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which British tennis player was born on May 15, 1987 and was ranked world No. 1 by the Association of Tennis Professionals for 41 weeks?',\n",
       "  'output': 'Quel joueur de tennis Britannique est né le 15 mai 1987 et a été classé numéro 1 mondial par l’Association of Tennis Professionals pendant 41 semaines ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was OPEC founded before 1960?',\n",
       "  'output': 'L’organisation des pays exportateurs de pétrole a-t-elle été créée avant 1960 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): As of 2021, how many books are in the Stormlight Archive series by Brandon Sanderson?',\n",
       "  'output': 'En 2021, combien de livres figurent dans la série Les Archives de Roshar, par Brandon Sanderson ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the longest river in the United States that is not named after the state where it begins?',\n",
       "  'output': 'Quel est la plus longue rivière aux États-Unis qui ne porte pas le nom de l’État où il commence ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the seventh book in The Wheel of Time series?',\n",
       "  'output': 'Quel est le septième livre de la série La Roue du temps ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries are in the Arctic Circle?',\n",
       "  'output': 'Combien de pays y a-t-il dans le cercle arctique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the longest song recorded?',\n",
       "  'output': 'Quelle est la plus longue chanson enregistrée ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Olympics has Aly Raisman competed in?',\n",
       "  'output': 'À combien de Jeux Olympiques Aly Raisman a-t-elle participé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first king of Sweden?',\n",
       "  'output': 'Qui était le premier roi de Suède ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Pirates of the Caribbean movie had the largest budget?',\n",
       "  'output': 'Quel film de la série Pirates des Caraïbes avait le plus gros budget ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was King Henry VIII married to for the least amount of time?',\n",
       "  'output': 'Comment s’appelle la femme avec qui le roi Henri VIII s’est marié pendant un bref moment ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has a larger population, Colombia or Argentina?',\n",
       "  'output': 'Quel pays est-il le plus peuplé, la Colombie ou l’Argentine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Gibb brother was not a member of the Bee Gees?',\n",
       "  'output': 'Quel frère Gibb n’était pas membre de BeeGees ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many states does Mexico touch?',\n",
       "  'output': 'Combien d’États le Mexique touche-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What U.S. state is not contiguous with continental North America?',\n",
       "  'output': 'Quel État américain n’est pas contigu à l’Amérique du Nord continentale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country is bigger in size, USA or China?',\n",
       "  'output': 'Entre les USA et la Chine : quel pays a la plus grande superficie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is Juliet's last name in Romeo and Juliet?\",\n",
       "  'output': 'Quel est le nom de famille de Juliette dans Roméo et Juliette ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who has won the most Hugos for Best Novel?',\n",
       "  'output': 'Qui a remporté le plus de prix Hugo du meilleur roman ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Author who has written the most books?',\n",
       "  'output': 'Quel auteur a écrit le plus de livres ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which New England state did Al Gore not win in the 2002 Presidential Election?',\n",
       "  'output': 'Dans quel État de Nouvelle-Angleterre Al Gore n’a-t-il pas remporté l’élection présidentielle de 2002 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which U.S. states are not part of the contiguous United States?',\n",
       "  'output': 'Quels États ne font pas partie des États-Unis contigus ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has more area, Canada or the United States?',\n",
       "  'output': 'Quel pays a une plus grande superficie : le Canada ou les États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What state did the American Civil War begin in?',\n",
       "  'output': 'Dans quel État la Guerre de Sécession américaine a-t-elle commencé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did the Seattle Seahawks win the Super Bowl in 2014?',\n",
       "  'output': 'Les Seakawks de Seattle ont-ils gagné le Super Bowl en 2014 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Japanese island was the site of a bloody battle during World War II and is now the host of a US military base?',\n",
       "  'output': 'Quelle île japonaise a été le théâtre d’une bataille sanglante pendant la Seconde Guerre mondiale et est désormais une base militaire américaine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who directed the movie that was based on the first book of the Hobbit?',\n",
       "  'output': 'Qui a réalisé le film inspiré du premier livre Hobbit ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the last king of Sparta?',\n",
       "  'output': 'Qui était le dernier roi de Sparte ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): For which movie was Eddie Redmayne nominated for an Academy Award for Best Actor but did not win?',\n",
       "  'output': 'Pour quel film Eddie Redmayne avait-il été nominé pour un Oscar de meilleur acteur mais ne l’a pas remporté ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Olympics has Suni Lee competed in?',\n",
       "  'output': 'À combien de Jeux olympiques Suni Lee a-t-elle participé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What river flows North to South and is the longest river in North America?',\n",
       "  'output': 'Quel fleuve coule du Nord au Sud et est le plus long d’Amérique du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Were the Detroit Red Wings part of the original 8 NHL teams?',\n",
       "  'output': 'Les Red Wings de Détroit faisaient-ils partie des 8 équipes d’origine de NHL ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the biggest city in Scotland?',\n",
       "  'output': 'Quelle est la plus grande ville écossaise ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): When was the last game in Assassin's Creed released for PlayStation 5 in Europe?\",\n",
       "  'output': 'Quand est sorti le dernier jeu Assassin’s Creed sur Playstation 5 en Europe ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many times has Nancy Pelosi been House Minority Leader?',\n",
       "  'output': 'Combien de fois Nancy Pelosi a-t-elle dirigé la Chambre des représentants ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the president of Ireland?',\n",
       "  'output': 'Qui est le Président de l’Irlande ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Avengers or The Lion King have the highest budget in 2019?',\n",
       "  'output': 'Avengers ou le Roi Lion ont-ils eu le plus gros budget en 2019 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What was Billy Squire's first album called?\",\n",
       "  'output': 'Quel était le titre du premier album de Billy Squire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many States were originally part of the United States?',\n",
       "  'output': 'Combien d’états faisaient partie originairement des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who had a female leader first, United Kingdom or India?',\n",
       "  'output': 'Qui a eu une femme dirigeante en premier, le Royaume-Uni ou l’Inde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many square miles is the Florida state capital?',\n",
       "  'output': 'Quelle est la superficie en miles carrés de la capitale de l’État de Floride ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the net worth of the Canadian \"Yummy\" singer?',\n",
       "  'output': 'Quel est l’avoir net du chanteur Canadien « Yummy » ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first king of England?',\n",
       "  'output': 'Qui était le premier Roi d’Angleterre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What war did the author of Nineteen Eighty-four fight in?',\n",
       "  'output': 'Dans quelle guerre l’auteur de 1984 a-t-il combattu ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the birthplace of the first black United States president?',\n",
       "  'output': 'Quel était le lieu de naissance du premier président noir des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which member of Destiny's Child appeared in the movie Dreamgirls?\",\n",
       "  'output': 'Quel membre des Destiny’s Child apparaît dans le film Dreamgirls ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Italy part of the Axis alliance in World War II?',\n",
       "  'output': 'L’Italie faisait-elle partie de l’alliance de l’Axe pendant la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many US presidents were from California?',\n",
       "  'output': 'Combien de présidents américains étaient originaires de la Californie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Pulitzer Prizes has John Updike won?',\n",
       "  'output': 'Combien de prix Pulitzer John Updike a-t-il remportés ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was the French military and political leader who rose to prominence during the French Revolution when he became emperor of France?',\n",
       "  'output': 'Quel âge avait le militaire Français et le dirigeant politique qui est monté en puissance pendant la Révolution française lorsqu’il est devenu empereur de France ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who led the first Roman invasion of Britain?',\n",
       "  'output': 'Qui a dirigé la première invasion romaine de Grande-Bretagne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who won the 2019 World Series?',\n",
       "  'output': 'Qui a remporté la Série mondiale de deux mille dix neuf ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many times have the Minnesota Twins won the World Series?',\n",
       "  'output': 'Combien de fois le Minnesota Twins ont-ils gagné la Série mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries are in Eastern Europe?',\n",
       "  'output': 'Combien de pays y a-t-il en Europe de l’Est ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the last state to join the USA?',\n",
       "  'output': 'Quel était le dernier État à rejoindre les États Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What states are not part of the mainland in the US?',\n",
       "  'output': 'Quels États des États-Unis ne font pas partie du continent ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest country in the world by total area?',\n",
       "  'output': 'Quel est le plus grand pays du monde par sa superficie totale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries in Asia have a total area of under 1,000 square miles?',\n",
       "  'output': 'Combien de pays d’Asie ont une superficie totale inférieure à 1 000 miles carrés ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many authors wrote books in the Wheel of Time series?',\n",
       "  'output': 'Combien d’auteurs ont écrit les livres de la série La roue du temps ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did Germany invade Poland?',\n",
       "  'output': 'Quand l’Allemagne a-t-elle envahi la Pologne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does South Carolina have a larger population than North Carolina?',\n",
       "  'output': 'La Caroline du Sud est-elle plus peuplée que la Caroline du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the second best-selling album in the US of the 1990s?',\n",
       "  'output': 'Dans les années 1990, quel album fut second au palmarès des meilleures ventes aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does Tom Brady play for the New Orleans Saints?',\n",
       "  'output': 'Tom Brady joue-t-il pour les Saints de la Nouvelle-Orléans ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which The Sandlot movie made the most money?',\n",
       "  'output': 'Lequel des films Le Gang des champions rapporta le plus ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which civilization was known for mummifying their dead?',\n",
       "  'output': 'Quelle civilisation était connue pour momifier ses morts ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the president of Bolivia?',\n",
       "  'output': 'Qui est le Président de la Bolivie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the current president of South Africa?',\n",
       "  'output': 'Qui est l’actuel Président d’Afrique du Sud ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which French leader invaded Mexico, but never conquered it?',\n",
       "  'output': 'Quel dirigeant français a envahi le Mexique mais ne l’a jamais conquis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the Statue of Liberty built?',\n",
       "  'output': 'Quand a été construite la Statue de la Liberté ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the only member of the Lewis and Clark expedition not to survive the journey?',\n",
       "  'output': 'Quel est le seul membre de l’expédition Lewis et Clark à n’avoir pas survécu au voyage ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Canadian Provinces do not border the USA?',\n",
       "  'output': 'Quelles provinces canadiennes ne bordent pas les États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the oldest U.S. senator at time of retirement or death?',\n",
       "  'output': 'Qui a été le sénateur des États-Unis le plus âgé au moment de sa retraite ou de son décès ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who wrote the Diary of a Wimpy Kid books?',\n",
       "  'output': 'Qui a écrit les tomes du Journal d’un dégonflé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which is the longest river in the United States, the Mississippi or the Missouri?',\n",
       "  'output': 'Quel est le plus long fleuve des États-Unis, le Mississippi ou le Missouri ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who won Best Actress at the 2016 Academy Awards?',\n",
       "  'output': 'Qui a remporté l’Oscar de la meilleure actrice à la cérémonie des Oscars de deux mille seize ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Pixar make Antz?',\n",
       "  'output': 'Pixar a-t-il réalisé Fourmiz ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is the BJP the only party in India to have won a majority without forming a coalition since 1984?',\n",
       "  'output': 'Le BJP est-il le seul parti en Inde a avoir remporté une majorité sans former une coalition depuis 1984 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What state does Scarlett O'hara's family live in?\",\n",
       "  'output': 'Dans quel État, la famille de Scarlett O’Hara habite-t-elle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did the author who wrote The Martian Chronicles die?',\n",
       "  'output': 'Quand l’auteur des Chroniques martiennes est-il décédé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many states does the Mississippi River run though or along the border of?',\n",
       "  'output': 'Combien d’États le fleuve Mississippi traverse-t-il ou borde-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Avengers: Age of Ultron or Avengers: Endgame make more worldwide gross?',\n",
       "  'output': 'Avengers : L’Ère d’Ultron et Avengers : Endgame a fait plus de recettes mondiales ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which of the three main heroes Luke, Leia and Han Solo in the first Star Wars Trilogy refused to sign a three picture deal?',\n",
       "  'output': 'Qui, parmi les trois principaux héros de la première trilogie de Star Wars, à savoir Luke Leia et Han Solo, a refusé de signer un contrat pour jouer dans les trois films ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the second longest river in the USA?',\n",
       "  'output': 'Quelle est la deuxième plus longue rivière des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was elected president of the United States and not make it past 40 days in office?',\n",
       "  'output': 'Qui a été élu président des États-Unis et n’a pas dépassé 40 jours au pouvoir ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Frozen movies are there?',\n",
       "  'output': 'Combien y a-t-il de films La Reine des neiges ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did The Cold War end?',\n",
       "  'output': 'Quand la Guerre Froide a-t-elle pris fin ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which country has competed the most times in the Summer Olympics and hasn't won a gold medal?\",\n",
       "  'output': 'Quel pays a participé le plus grand nombre de fois aux Jeux olympiques d’été et n’a remporté de médaille d’or ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third highest point on Earth?',\n",
       "  'output': 'Quel est le troisième point le plus élevé sur Terre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which actress starred in the first two Mummy movies but not the third one?',\n",
       "  'output': 'Quel est l’actrice qui a joué dans les deux premiers films La Momie, mais pas dans le troisième ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What was Mariam's husband's name in Land of One Thousand Splendid Suns?\",\n",
       "  'output': 'Comment s’appelait le mari de Mariam dans le roman Mille soleils splendides ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is there a character called Holden Caulfield in The Catcher in the Rye?',\n",
       "  'output': 'Y a-t-il un personnage nommé Holden Caulfield dans L’Attrape-cœurs ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries were part of the Entente Powers during World War I?',\n",
       "  'output': 'Combien de pays étaient membres de l’entente de puissance pendant la première guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Have the A's been to a World Series since the 90s?\",\n",
       "  'output': 'Les A’s ont-ils participé à une Série mondiale depuis les années 1990 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Welcome to Dead House the first book in the Goosebumps series?',\n",
       "  'output': 'Le roman La Maison des morts est-il le premier livre de la série Chair de poule ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has the most salt lakes, Canada or Russia?',\n",
       "  'output': 'Quel pays a le plus grand nombre de lacs salés, le Canada ou la Russie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many World Wars happened in the 1900s?',\n",
       "  'output': 'Il y a eu combien de guerres mondiales dans les années 1900 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the largest city by population located in the world's smallest continent?\",\n",
       "  'output': 'Quelle est la plus grande ville par sa population située sur le plus petit continent du monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Lord of the Rings movies are there?',\n",
       "  'output': 'Combien de films de la série Le Seigneur des anneaux existe-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the longest surviving child of King Louis XVI of France?',\n",
       "  'output': 'Qui était le plus ancien enfant survivant du roi Louis XVI de France ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How tall is the singer of Big Girls Don't Cry?\",\n",
       "  'output': 'Quelle taille fait la chanteuse de Big Girls Don’t Cry ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many boroughs make up Greater London?',\n",
       "  'output': 'Combien de quartiers forment le Grand Londres ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who wrote The Vampire Chronicles?',\n",
       "  'output': 'Qui a écrit la Chronique des vampires ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which war lasted longer, the Vietnam War or World War I?',\n",
       "  'output': 'Quelle guerre a duré plus longtemps : la guerre du Vietnam ou la Première Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Where is Mount Rushmore located?',\n",
       "  'output': 'Où se trouve le mont Rushmore ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which book in the Wheel of Time series was released in 1991?',\n",
       "  'output': 'Quel livre de la série La Roue du temps est sorti en 1991 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What movie had ghosts in it and had a villain trapped in a painting?',\n",
       "  'output': 'Dans quel film y avait-il des fantômes ainsi qu’un méchant enfermé dans un tableau ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did The Twilight Saga: New Moon come out before 1995?',\n",
       "  'output': 'Twilight, chapitre II : Tentation est-il sorti avant 1995 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How many Circles of Hell are in Dante's Inferno?\",\n",
       "  'output': 'Combien de cercles de l’Enfer y a-t-il dans l’Enfer de Dante ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Democrat governors has Louisiana had since 2000?',\n",
       "  'output': 'Combien de gouverneurs démocrates la Louisiane a-t-elle eu depuis 2000 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is a current senator of California who was also mayor of San Francisco from 1978 to 1988?',\n",
       "  'output': 'Qui est un actuel sénateur de Californie qui a également été maire de San Francisco de 1978 à 1988 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who won the Presidential Election in 1904?',\n",
       "  'output': 'Qui a remporté l’élection présidentielle en mille neuf cent quatre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who won the 1947 Oscar for Best Actress?',\n",
       "  'output': 'Qui a remporté l’Oscar de la meilleure actrice en 1947 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Has the United States of America ever had a female president?',\n",
       "  'output': 'Y a-t-il déjà eu une femme présidente des États-Unis d’Amérique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Super Bowls have the Tampa Bay Buccaneers won?',\n",
       "  'output': 'Combien de Super Bowls les Buccaneers de Tampa Bay ont-ils gagnés ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Titanic and Ghostbusters come out in the same year?',\n",
       "  'output': 'Titanic et SOS Fantômes sont-ils sortis la même année ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the last emperor of China?',\n",
       "  'output': 'Qui était le dernier empereur de Chine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Godfather movies are there?',\n",
       "  'output': 'Combien de films Le Parrain y a-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Beyoncé get a twenty seventh Grammy this year?',\n",
       "  'output': 'Beyonce a-t-elle obtenu un vingt-septième Grammy cette année ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which movie in 1998 was Ian McKellen nominated for Best Actor in a Leading Role but lost?',\n",
       "  'output': 'Pour quel film de 1998 Ian Mckellen a-t-il été nominé pour l’Oscar du meilleur acteur, mais a perdu ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the daughter of Augustus and the second wife of the Emperor Tiberius?',\n",
       "  'output': 'Quelle était la fille d’Auguste à être la deuxième femme de l’empereur Tibère ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Back to the Future movie made the least money?',\n",
       "  'output': 'Quel film Retour vers le future a fait le moins de recettes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Was Stephen King's The Stand published before 1980?\",\n",
       "  'output': 'Le Fléau de Stephen King a-t-il été publié avant 1980 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries are in Southeastern Asia but not part of the Asian Tigers?',\n",
       "  'output': 'Combien de pays se trouvent dans l’Asie du Sud-Est mais ne font pas partie des tigres asiatiques ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which player in the south has the most steals per game in an NBA season?',\n",
       "  'output': 'Quel joueur du sud est le recordman des interceptions par match en une saison de la NBA ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Catch-22 released before Silent Spring?',\n",
       "  'output': 'Catch 22 a-t-il été publié avant Printemps silencieux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Is The Handmaid's Tale the same as To Kill a Mockingbird?\",\n",
       "  'output': 'La Servante écarlate est-elle la même chose que Ne tirez pas sur l’oiseau moqueur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many United States presidents have been assassinated?',\n",
       "  'output': 'Combien de présidents des États-Unis ont été assassinés ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many video games have more than 140,000,000 sales?',\n",
       "  'output': 'Combien de jeux vidéo ont dépassé les 140 000 000 de ventes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who holds the record for most triple doubles all time?',\n",
       "  'output': 'Qui détient le record du triple double de tous les temps ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third largest lake in the United States?',\n",
       "  'output': 'Quel est le troisième plus grand lac des États-unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which lake is part of the Great Lakes and shares the name of a Canadian province?',\n",
       "  'output': 'Quel lac fait partie des Grands Lacs et partage son nom avec une province canadienne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How many members were originally in Destiny's Child?\",\n",
       "  'output': 'Combien de membres comptait le groupe Destiny’s Child au départ ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state has more electoral votes, South Carolina or North Carolina?',\n",
       "  'output': 'Quel État a le plus de votes électoraux, la Caroline du Sud ou la Caroline du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did The Great Gatsby published in 1924?',\n",
       "  'output': 'Gatsby le Magnifique a-t-il été publié en 1924 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Los Angeles the capital of California?',\n",
       "  'output': 'Los Angeles est-elle la capitale de la Californie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was The Catcher in the Rye published after 1970?',\n",
       "  'output': 'L’Attrape-cœurs a-t-il été publié après 1970 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what year did the author who wrote To Kill a Mockingbird die?',\n",
       "  'output': 'En quelle année disparaissait l’auteur de Ne tirez pas sur l’oiseau moqueur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Queen Elizabeth I rule England and Ireland for over 40 years?',\n",
       "  'output': 'La reine Élisabeth I a-t-elle dirigé l’Angleterre et l’Irlande pendant plus de 40 ans ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which football player plays for Liverpool and also plays for Egypt?',\n",
       "  'output': 'Quel footballeur joue au Liverpool, mais aussi pour l’Égypte ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the highest court in Africa?',\n",
       "  'output': 'Quelle est la plus haute juridiction en Afrique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was USA at the end of WWII?',\n",
       "  'output': 'Quel âge avaient les États-Unis à la fin de la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the third Super Bowl the Green Bay Packers won?',\n",
       "  'output': 'Quand a eu lieu le troisième Super Bowl que les Packers de Green Bay ont remporté ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who served the most terms in office as the president of the United States?',\n",
       "  'output': 'Qui a eu le plus long mandat au poste de président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Where was Paul Atreides born?',\n",
       "  'output': 'Où est né Paul Atréides ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many US presidents were elected as members of the Whig Party?',\n",
       "  'output': 'Combien de présidents américains ont été élus en tant que membres du parti Whig ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many mainline Final Fantasy games released on the SNES in the USA?',\n",
       "  'output': 'Combien de jeux Final Fantasy sont sortis sur la SNES aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who won the Grammy for Best Vocal Jazz Album in 2020?',\n",
       "  'output': 'Qui a remporté le grammy award du meilleur album de jazz vocal en 2020 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which poet has won the most Pulitzer Prizes?',\n",
       "  'output': 'Quel poète a remporté le plus grand nombre de prix Pulitzer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which novella in the Stephen King collection Different Seasons was the first to be adapted as a movie?',\n",
       "  'output': 'Quelle nouvelle du recueil Différentes Saisons de Stephen King a été la première à être adaptée au cinéma ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What books in the series Diary of a Wimpy Kid were not adapted into a movie?',\n",
       "  'output': 'Quels livres de la série Journal d’un dégonflé n’ont pas été adaptés au cinéma ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the father of Ophelia and Laertes?',\n",
       "  'output': 'Qui est le père d’Ophélie et de Laërte ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old is the current manager of the Houston Astros?',\n",
       "  'output': 'Quel âge a le directeur actuel des Astros de Houston ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Itō Hirobumi the first prime minister of Japan?',\n",
       "  'output': 'Itō Hirobumi était-il le tout premier Premier ministre du Japon ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who designed Washington DC's Vietnam Veteran's Memorial?\",\n",
       "  'output': 'Qui a conçu le Mémorial des anciens combattants du Viêt Nam de Washington D. C. ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the 41st president of the United States and former CIA chief?',\n",
       "  'output': 'Qui était le 41e président des États-Unis et ancien chef de la CIA ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did King Henry V have six wives?',\n",
       "  'output': 'Le roi Henri V avait-il six femmes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year did T.S. Eliot publish The Waste Land?',\n",
       "  'output': 'En quelle année T. S. Eliot a-t-il publié La Terre vaine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country was an Axis Power, invaded Africa, and also joined the Allies in WW II?',\n",
       "  'output': 'Quel pays était une puissance de l’Axe, a envahi l’Afrique, et a aussi rejoint les alliés lors de 2e Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Citizen Kane win Best Picture at the Academy Awards?',\n",
       "  'output': 'Le film Citoyen Kane a-t-il remporté l’Oscar du meilleur film ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many states ratified the Articles of Confederation in America by 1781?',\n",
       "  'output': 'Combien d’États ont ratifié les articles de la confédération en Amérique en 1781 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the husband of the artist who painted The Wounded Deer?',\n",
       "  'output': 'Qui était le mari de l’artiste qui a peint le Cerf blessé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many states does the United Kingdom have?',\n",
       "  'output': 'Combien d’États le Royaume-Uni compte-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state does not share a border with more than one other state?',\n",
       "  'output': 'Quel État n’a pas de frontière commune avec plus d’un autre État ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many movies were made from the Lord of the Rings book series?',\n",
       "  'output': 'Combien de films ont été sortis à partir de la saga littéraire Le Seigneur des anneaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which countries in South America do not border an ocean?',\n",
       "  'output': 'Quels pays d’Amérique du Sud ne bordent pas un océan ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Grammy Awards did Beyoncé win in 2020?',\n",
       "  'output': 'Combien de Grammy Awards Beyonce a-t-elle remportés en 2020 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Romancing the Stone filmed in Colombia?',\n",
       "  'output': 'À la poursuite du diamant vert a-t-il été tourné en Colombie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who wrote the Emancipation Proclamation and was assassinated by John Wilkes Booth?',\n",
       "  'output': 'Qui rédigea la proclamation d’émancipation et fut assassiné par John Wilkes Booth ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the author who wrote Crime and Punishment born?',\n",
       "  'output': 'Quand est né l’auteur de Crime et Châtiment ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who wrote the book that the movie One Flew Over the Cuckoo's Nest is based on?\",\n",
       "  'output': 'Qui a écrit le livre dont s’inspire le film Vol au-dessus d’un nid de coucou ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many senators does the last state to join the United States have?',\n",
       "  'output': 'Combien de sénateurs compte le dernier État à rejoindre les États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Middle Eastern countries did George W. Bush say were part of the Axis of Evil?',\n",
       "  'output': 'Quel pays du Moyen-Orient faisait partie de l’Axe du Mal, selon George W. Bush ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which king marched towards India, but did not invade it?',\n",
       "  'output': 'Quel roi marcha vers l’Inde mais ne l’a pas envahi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was the 28th president of the U.S. when he died?',\n",
       "  'output': 'Quel âge avait le 28e Président des États-Unis à sa mort ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the population of the country where The Great Wall of China is located?',\n",
       "  'output': 'Quelle est la population du pays qui abrite la Grande Muraille de Chine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What was J.D. Salinger's first published book?\",\n",
       "  'output': 'Quel était le premier livre publié par J.D. Salinger ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was a prime minister of Great Britain and was born on November 30, 1874?',\n",
       "  'output': 'Qui était premier ministre de la Grande Bretagne et est né le 30 novembre 1874 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What party did the U.S. president belong to when the United States left Vietnam during the Vietnam war?',\n",
       "  'output': 'À quel parti appartenait le président des États-Unis lorsque les États-Unis ont quitté le Vietnam lors de la guerre du Vietnam ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which mountain is in the White Mountains and is the tallest in New Hampshire?',\n",
       "  'output': 'Quel montagne fait partie de la chaîne de montagnes Blanches et est le plus haut du New Hampshire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What war happened first, the Vietnam War or the Korean War?',\n",
       "  'output': 'Quelle guerre est survenue en premier, la guerre du Vietnam ou la guerre de Corée ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What are the only countries in Africa that speak English as a first language and not another language?',\n",
       "  'output': 'Quels sont les seuls pays d’Afrique qui ont l’anglais pour langue officielle et non pour langue secondaire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many United States Representatives does New Mexico have?',\n",
       "  'output': 'Combien de représentants des États-Unis le Nouveau-Mexique compte-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What came right after the New Kingdom in ancient Egypt?',\n",
       "  'output': 'Qu’est-ce qui est arrivé juste après le Nouveau Royaume en Égypte antique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the population of the country where Mount Vesuvius is located?',\n",
       "  'output': 'Quelle est la population du pays où se situe le Mont Vésuve ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many mathematicians won the 2015 Abel Prize?',\n",
       "  'output': 'Combien de mathématiciens ont remporté le prix Abel en 2015 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What city is known as Sin City?',\n",
       "  'output': 'Quelle ville est connue comme la Ville du Péché ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Hawaii considered a state in the USA?',\n",
       "  'output': 'Hawaï est-il considéré comme un État aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Where were the first Golden Globe Awards held at?',\n",
       "  'output': 'Où s’est tenue la première cérémonie des Golden Globes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country does not have more than 1,000 citizens?',\n",
       "  'output': 'Quel pays ne compte pas plus de 1000 citoyens ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the best-selling game on XBox of all time?',\n",
       "  'output': 'Quel est le jeu sur X Box le plus vendu de tous les temps ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest building in the capital city of Germany?',\n",
       "  'output': 'Quel est le plus haut bâtiment de la capitale de l’Allemagne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the first democratic country?',\n",
       "  'output': 'Quel était le premier pays démocratique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which English monarch had the longer reign, Queen Victoria or Elizabeth I?',\n",
       "  'output': 'Quelle monarque Anglaise a eu le plus long règne, la reine Victoria ou Élizabeth I ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first Egyptian Pharaoh?',\n",
       "  'output': 'Qui était le premier Pharaon d’Égypte ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which character was acting Deputy Director of the CIA and uncovered a secret war being waged in Colombia in Clear and Present Danger?',\n",
       "  'output': 'Quel personnage a joué le rôle de Directeur adjoint de la CIA et a découvert une guerre secrète menée en Colombie dans le film Clear and Present Danger ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Linda Ronstadt albums are not in English?',\n",
       "  'output': 'Quels albums de Linda Ronstadt n’étaient pas en anglais ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was a famous American author and an oyster pirate in his youth?',\n",
       "  'output': 'Quel auteur américain célèbre a pêché des huîtres dans sa jeunesse ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the shortest war in history?',\n",
       "  'output': 'Quelle a été la guerre la plus courte de l’Histoire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the 2nd largest Island in the world?',\n",
       "  'output': 'Quelle est la deuxième plus grande île au monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which river runs through the U.S. and has its mouth at the Bering Sea?',\n",
       "  'output': 'Quel fleuve traverse les États-Unis et a son embouchure dans la mer de Béring ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the population of Medford MA, USA?',\n",
       "  'output': 'Combien d’habitants compte Medford dans le Massachusetts, aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is R.L. Stine the author of the Goosebumps series?',\n",
       "  'output': 'R.L. Stine est-il l’auteur de la série Chair de poule ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state has more US representatives Pennsylvania or Ohio?',\n",
       "  'output': 'Quel est l’État qui compte le plus de représentants américains, la Pennsylvanie ou l’Ohio ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Where was the actor who played Achilles in Troy born?',\n",
       "  'output': 'Quel est le lieu de naissance de l’acteur qui a incarné Achille dans le film Troie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which book in Stephen King's The Dark Tower series was not a full length book?\",\n",
       "  'output': 'Quel livre de la série La Tour sombre de Stephen King n’était complet ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the last Pirate of the Caribbean movie released?',\n",
       "  'output': 'En quelle année le dernier film Pirates des Caraïbes est-il sorti ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the profession of the 33rd president of the United States prior to being elected to office?',\n",
       "  'output': 'Quelle profession exerçait le 33e président des États-Unis avant d’accéder au pouvoir ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which book of the Biblical Pentateuch does not include Moses as a character?',\n",
       "  'output': 'Dans quel ouvrage de la pentateuque de la Bible Moïse n’apparaît-il pas ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many movies are there in the Lord of the Rings series?',\n",
       "  'output': 'Combien de films comporte la saga cinématographique Le Seigneur des anneaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Mount Baker taller than Mount St. Helens?',\n",
       "  'output': 'Le mont Baker est-il plus haut que le mont Saint Helens ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Supreme Leaders has North Korea had?',\n",
       "  'output': 'La Corée du nord a déjà eu combien de leaders suprêmes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third oldest continuously inhabited city in Southeast Asia?',\n",
       "  'output': 'Quelle la troisième ville la plus ancienne, encore peuplée dans l’Asie du sud-est ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the 42nd president of the United States and former governor of Arkansas?',\n",
       "  'output': 'Qui était le 42e président des États-Unis et ancien gouverneur de l’Arkansas ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Nancy Pelosi a member of the U.S. House of Representatives?',\n",
       "  'output': 'Nancy Pelosi est-elle membre de la Chambre des représentants des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does California have more members of Congress than Montana?',\n",
       "  'output': 'La Californie a-t-elle plus de membres du Congrès que le Montana ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does Jordan have a King?',\n",
       "  'output': 'La Jordanie a t-elle un roi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many ships were in Columbus voyage to the Americas?',\n",
       "  'output': 'Combien de navires ont participé à l’expédition de Colomb aux Amériques ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the ethnicity of the author who wrote Gifted Hands?',\n",
       "  'output': 'Quelle est l’origine ethnique de l’auteur Des mains en or ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who was a member of the 2004 U.S. Olympic men's swim team and born in Irvine, California?\",\n",
       "  'output': 'Quel membre de l’équipe olympique masculine de natation des États-Unis de 2004 est né à Irvine, en Californie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What former vice president ran for congress in 1988 and ran for the U.S. House of Representatives again in 2000?',\n",
       "  'output': 'Quel ancien vice-président s’est présenté au Congrès en 1988 et s’est à nouveau présenté à la Chambre des représentants des États-Unis en 2000 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the principal author of the Declaration of Independence and the third president of the United States?',\n",
       "  'output': 'Quel a été l’auteur principal de la Déclaration d’indépendance et le troisième président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which city will be the first to host both the summer Olympics and the winter Olympic Games?',\n",
       "  'output': 'Quelle sera la première ville à avoir accueilli les Jeux olympiques d’été et d’hiver ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How many members are in Denmark's Parliament?\",\n",
       "  'output': 'Combien de membres le parlement danois comprend-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the armed conflict within a nation called?',\n",
       "  'output': 'Qu’est-ce qu’un conflit armé au sein d’une nation ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the first Smash Bros game to include Princess Peach?',\n",
       "  'output': 'Quel était le premier jeu Smash Bros à intégrer la princesse Peach ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the most admired award for singing?',\n",
       "  'output': 'Quel est le Prix le plus prestigieux pour la chanson ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is the Great Gatsby set in 1994?',\n",
       "  'output': 'Gatsby le Magnifique se déroule-t-il en 1994 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Diary of a Wimpy Kid are there?',\n",
       "  'output': 'Combien de tomes compte la série Journal d’un dégonflé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did T.Rex have number one hits in the UK?',\n",
       "  'output': 'T. Rex a-t-il été classé numéro 1 au Royaume-Uni ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who spent more time in power, King George VI or Queen Elizabeth II?',\n",
       "  'output': 'Qui a passé plus de temps au pouvoir, le roi George VI ou la reine Élisabeth II ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is an American professional golfer who did not play professional golf from December 2009 to early April 2010 in an attempt to resolve marital issues?',\n",
       "  'output': 'Comment s’appelle un golfeur professionnel Américain qui n’a pas joué au golf professionnel de décembre 2009, début avril 2010 pour tenter de résoudre des problèmes conjugaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Have the Tampa Bay Lightning won more Stanley Cups than the Montreal Canadiens?',\n",
       "  'output': 'Est-ce que le Lightning de Tampa Bay a remporté plus de coupes Stanley que les Canadiens de Montréal ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How many Assassin's Creed games are set in ancient Egypt?\",\n",
       "  'output': 'Combien de jeux Assassin’s Creed se déroulent en Égypte antique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Electoral Votes does Pennsylvania have?',\n",
       "  'output': 'Combien de collège électoral y a-t-il en Pennsylvanie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many U.S. presidents were born in Georgia?',\n",
       "  'output': 'Combien de présidents américains sont nés en Géorgie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first leader and founder of North Korea?',\n",
       "  'output': 'Qui était le premier leader et fondateur de la Corée du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the oldest person to win the Academy Award for Best Actor?',\n",
       "  'output': 'Qui est la plus vieille personne à remporter l’Oscar de Meilleur acteur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the fifth president of the United States?',\n",
       "  'output': 'Qui a été le cinquième président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest building in the country where Mount Rushmore is located?',\n",
       "  'output': 'Quel est le plus haut bâtiment du pays où se trouve le Mont Rushmore ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was the longest serving congressman in United States history when he died?',\n",
       "  'output': 'Quel âge avait à sa mort le membre du Congrès ayant la plus grande longévité en fonction de l’histoire des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many World Series has Derek Jeter won?',\n",
       "  'output': 'Combien de Séries mondiales Derek Jeter a-t-il gagnées ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What country has the capital with the most population?',\n",
       "  'output': 'Quel pays a la capitale la plus peuplée ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Chambers of Congress are there?',\n",
       "  'output': 'Combien y a-t-il de Chambres au Congrès ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Animal Farm come out after 1990?',\n",
       "  'output': 'La Ferme des animaux est-il sorti après 1990 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Mark Twain write A Christmas Carol?',\n",
       "  'output': 'Mark Twain a-t-il écrit Un chant de Noël ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is the United States larger than Canada by area?',\n",
       "  'output': 'Les États-Unis sont-ils plus grands que le Canada en termes de superficie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the youngest author of a best-selling book?',\n",
       "  'output': 'Qui est le plus jeune auteur d’un best-seller ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the sixth game in the original Mega Man series released in the U.S.?',\n",
       "  'output': 'Quand est sorti le sixième jeu de la série originale Mega Man aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year did the Mongol Empire begin?',\n",
       "  'output': 'En quelle année a débuté l’Empire mongol ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which African nation was never colonized by a European power?',\n",
       "  'output': 'Quelle nation Africaine n’a jamais été colonisée par une puissance Européenne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has produced the most heavy metal bands?',\n",
       "  'output': 'Quel pays a produit le plus grand nombre de groupes de heavy metal ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the last absolute monarch of Russia?',\n",
       "  'output': 'Qui était le dernier monarque absolu de Russie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the main character in the Pirates of the Caribbean franchise?',\n",
       "  'output': 'Qui est le personnage principal de la franchise Pirates des Caraïbes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was Alexander the Great when he became king?',\n",
       "  'output': 'Quel âge avait Alexandre le Grand lorsqu’il est devenu roi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which military alliance did not win World War II?',\n",
       "  'output': 'Quelle alliance militaire n’a pas gagné la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest building in the capital city of Argentina?',\n",
       "  'output': 'Quel est l’édifice le plus haut de la capitale de l’Argentine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many United States presidents did not have any biological children?',\n",
       "  'output': 'Combien de présidents des États-Unis n’avaient pas d’enfants biologiques ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did Adele first perform at the Grammy Awards?',\n",
       "  'output': 'Quand est-ce qu’Adèle a presté pour la première fois au Grammy Awards ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first Hispanic senator in United States?',\n",
       "  'output': 'Qui a été le premier sénateur hispanique des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was the third Roman emperor when he died?',\n",
       "  'output': 'Quel âge avait le troisième empereur romain quand il est mort ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many gold medals did Greg Louganis win for Olympic Diving?',\n",
       "  'output': 'Combien de médailles d’or Greg Louganis a remporté au plongeon olympique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What player has the most career home runs?',\n",
       "  'output': 'Quel joueur détient le record du nombre de coups de circuits sur une carrière ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has a larger population, America or UK?',\n",
       "  'output': 'Quel pays a une population plus importante : l’Amérique ou le Royaume-Uni ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): During the Civil War, what battle had the most casualties?',\n",
       "  'output': 'Pendant la Guerre de Sécession, quelle bataille avait le bilan le plus lourd ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first president of the United States and a general in the Continental Army?',\n",
       "  'output': 'Qui était le premier président des États-Unis et un général dans l’armée continentale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the second Goosebumps book released in 1997?',\n",
       "  'output': 'Quel était le deuxième livre à avoir été publié dans la série Chair de poule en 1997 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the owner of the Philadelphia Eagles?',\n",
       "  'output': 'Qui est propriétaire des Eagles de Philadelphie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Leonardo DiCaprio get the Oscar for Best Actor in Once Upon a Time in Hollywood?',\n",
       "  'output': 'Leonardo DiCaprio a-t-il gagné l’Oscar du meilleur acteur pour son rôle dans Once Upon a Time... in Hollywood ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which member of the 2021 U.S. Olympic women's gymnastics team has 3 individual gold medals and sat out for the 2021 team final?\",\n",
       "  'output': 'Quel membre de l’équipe olympique féminine de gymnastique des États-Unis a remporté trois médailles d’or individuelles et n’a pas participé à la finale des équipes de 2021 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): During the Battle of the Little Bighorn, which fighting force did not win?',\n",
       "  'output': 'Pendant la bataille de Little Bighorn, quelle force de combat n’a-t-elle pas gagné ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which movie was released first, Avengers: Endgame or Joker?',\n",
       "  'output': 'Quel film est sorti en premier, Avengers : Endgame ou Joker ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest mountain in the contiguous U.S. by elevation (feet)?',\n",
       "  'output': 'Quelle est la plus haute montagne des États-Unis contigus en termes d’altitude (pieds) ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Has there ever been an atheist U.S. president?',\n",
       "  'output': 'Y a-t-il déjà eu un président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the coach for Miami Heat from 1981 to 1995?',\n",
       "  'output': 'Qui a été l’entraîneur des Heat de Miami de mille neuf cent quatre-vingt-onze à mille neuf cent quatre-vingt-quinze ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did the Atlanta Falcons win a Super Bowl?',\n",
       "  'output': 'Les Falcons d’Atlanta ont-ils gagné un Super Bowl ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the first Series of Unfortunate Events book?',\n",
       "  'output': 'Quel est le premier livre des Désastreuses Aventures des orphelins Baudelaire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who is the adoptive brother of the main character of Assassin's Creed Valhalla?\",\n",
       "  'output': 'Qui est le frère adoptif du personnage principal d’Assassin’s Creed Valhalla ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did the novel Nineteen Eighty-four come out before 1984?',\n",
       "  'output': 'Le roman 1984 a-t-il été publié avant 1984 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many states are in the United States?',\n",
       "  'output': 'Combien d’États y a-t-il aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the king of Jerusalem who could not move his limbs due to leprosy?',\n",
       "  'output': 'Quel est le roi de Jérusalem qui ne pouvait pas bouger ses jambes à cause de la lèpre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many electoral votes did Hillary Clinton receive in the 2016 Election?',\n",
       "  'output': 'Combien de grands électeurs ont été remportés par Hilary Clinton lors de l’élection de deux mille seize ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who wrote Journey to the Center of the Earth?',\n",
       "  'output': 'Qui a écrit le script du film Voyage au centre de la terre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which current (2021) Texas senator was not born in the U.S.?',\n",
       "  'output': 'Quel sénateur du Texas actuel (2021) n’est pas né aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was president during the Vietnam War and the Bay of Pigs?',\n",
       "  'output': 'Qui était président pendant la guerre du Vietnam et la baie des Cochons ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which MLB team has the most World Series wins?',\n",
       "  'output': 'Quelle équipe de MLB a le plus de victoires en Série mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Robert Frost win a Pulitzer Prize?',\n",
       "  'output': 'Robert Frost a-t-il rempoté un prix Pulitzer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which of the Great Lakes does not touch Canada?',\n",
       "  'output': 'Parmi les Grands Lacs, lequel ne traverse pas le Canada ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did Mount Fuji first erupt?',\n",
       "  'output': 'Quand le mont Fuji est-il entré en éruption pour la première fois ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How many different NBA teams has Amar'e Stoudemire played for?\",\n",
       "  'output': 'Pour combien de différents équipes de la NBA Amar’e Stoudemire a-t-il joué ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Was the first Assassin's Creed game released before the Prince of Persia: Sands of Time trilogy?\",\n",
       "  'output': 'Le premier jeu Assassin’s Creed est-il sorti avant la trilogie Prince of Persia : Les Sables du Temps ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the population of the second most populous city in China?',\n",
       "  'output': 'Quel est le nombre d’habitants de la deuxième plus grande ville de Chine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Japanese monarch had the longest reign?',\n",
       "  'output': 'Quel monarque Japonais a eu le règne le plus long ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the name of the second Fast & Furious movie?',\n",
       "  'output': 'Quel est le titre du deuxième film Fast and Furious ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was a wife of Stephen III and the daughter of Bernabò Visconti?',\n",
       "  'output': 'Qui a été la femme d’Étienne III et la fille de Bernabò Visconti ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the longest river in England?',\n",
       "  'output': 'Quel est le fleuve le plus long d’Angleterre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the longest road in the world?',\n",
       "  'output': 'Quelle est la plus longue route du monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What was the name of the first king of England's grandfather?\",\n",
       "  'output': 'Quel était le nom du grand-père du premier roi d’Angleterre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the name of a system of mountains in eastern to northeastern North America that does not run through Florida?',\n",
       "  'output': 'Quel est le nom d’un système de montagnes qui s’étend de l’est au nord-est de l’Amérique du Nord mais qui ne traverse pas la Floride ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What was R.E.M.'s last studio album called?\",\n",
       "  'output': 'Quel a été le dernier album studio de R.EM. ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the leader of the country that was the first to put a satellite in orbit?',\n",
       "  'output': 'Qui est le dirigeant du premier pays à avoir mis un satellite en orbite ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which war resulted in more American lives lost, the Vietnam War or the war in Iraq?',\n",
       "  'output': 'Quelle guerre a abouti à plus de décès d’Américains, la guerre du Vietnam ou la guerre en Irak ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Fire type Pokemon could not be caught in the wild in Pokemon Yellow?',\n",
       "  'output': 'Quel Pokémon de type feu ne peut pas être capturé à l’état sauvage dans Pokémon Jaune ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what year did the Seattle Seahawks sign Russell Wilson as quarterback?',\n",
       "  'output': 'En quelle année les Seahawks de Seattle ont-ils signé Russell Wilson au poste de quart-arrière ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the name of the mountain range that borders both Russia and the country whose capital is Ulaanbaatar?',\n",
       "  'output': 'Quel est le nom de la chaîne de montagnes limitrophe avec la Russie et le pays dont la capitale est Ulaanbaatar ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What game in the Battlefield series was set during World War I?',\n",
       "  'output': 'Quel jeu de la série Battlefield se déroule pendant la Première Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the mentor of the author of the Red Mars trilogy?',\n",
       "  'output': 'Qui a été le mentor de l’auteur de la trilogie Mars la rouge ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which video game developer developed the 2nd-highest selling video game of all time?',\n",
       "  'output': 'Quel développeur de jeux vidéo a développé le 2e jeu vidéo le plus vendu de tous les temps ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is running for Senate against Republican Lindsey Graham in South Carolina in the 2020 Election?',\n",
       "  'output': 'Qui était candidat au Sénat contre le Républicain Lindsey Graham en Caroline du Sud à l’élection de 2020 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was the longest serving senator from Hawaii when he died?',\n",
       "  'output': 'Quel âge avait le plus ancien sénateur d’Hawaï lorsqu’il est mort ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many detective novels did the author of Murder on the Orient Express write?',\n",
       "  'output': 'Combien de romans policiers l’auteur de Le Crime de l’Orient-Express a-t-il écrit ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third book in the Jedi Apprentice series?',\n",
       "  'output': 'Quel est le troisième tome de la série Les Apprentis Jedi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the Pope at the beginning of this current millennium 2000 AD?',\n",
       "  'output': 'Qui était pape au début de l’actuel millénaire, en 2000 après J.-C. ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does the story in The Wonderful Adventures of Nils take place in Sweden?',\n",
       "  'output': 'L’histoire dans Le Merveilleux Voyage de Nils Holgersson se déroule-t-elle en Suède ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who ran for president in 2020 and graduated from Clemson University?',\n",
       "  'output': 'Qui s’est présenté à la présidence en 2020 et est diplômé de l’université de Clemson ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the population of Moscow, Russia?',\n",
       "  'output': 'Combien d’habitants compte Moscou, en Russie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was president of the United States and president of the Screen Actors Guild?',\n",
       "  'output': 'Qui a été président des États-Unis et président de la Screen Actor Guild ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): The third Fallout game took place in which area of the United States?',\n",
       "  'output': 'Dans quelle région des États-Unis le troisième jeu Fallout se déroulait-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Lord of the Rings book has the most words?',\n",
       "  'output': 'Quel livre de la série Le Seigneur des anneaux a le plus de mots ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries in Asia have a population under 1,000,000?',\n",
       "  'output': 'Combien de pays d’Asie ont une population inférieure à 1000 000 d’habitants ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What party did the U.S. president during WWII belong to?',\n",
       "  'output': 'À quel parti appartenait le président des États-Unis de l’époque de la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the second child of the king of England from 9 November 1841 to 6 May 1910 to die?',\n",
       "  'output': 'Qui a été le deuxième enfant du roi d’Angleterre du 9 novembre 1841 au 6 mai 1910 à mourir ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Leonardo da Vinci paint The Last Supper?',\n",
       "  'output': 'Léonard de Vinci a-t-il peint la Cène ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the third Lord of the Rings movie to be released?',\n",
       "  'output': 'Quel est le troisième film de la série Le Seigneur des anneaux à être sorti ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year did the Phillies win their first World Series?',\n",
       "  'output': 'En quelle année les Phillies ont-ils remporté leur première Série mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What day was the last volcanic eruption on the island of Hawaii?',\n",
       "  'output': 'De quand date la dernière éruption volcanique sur l’île d’Hawaï ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country borders the Mediterranean Sea and the Black Sea?',\n",
       "  'output': 'Quel pays borde la mer Méditerranée et la mer Noire ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which of the Great Lakes does not touch Michigan?',\n",
       "  'output': 'Parmi les Grands Lacs, lequel ne touche pas le Michigan ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is Camilla Cabello's best-selling hit?\",\n",
       "  'output': 'Quel est le tube le plus vendu de Camilla Cabello ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the fifth smallest country in the world by land mass?',\n",
       "  'output': 'Quel est le cinquième plus petit pays du monde en termes de superficie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which is the longest book series?',\n",
       "  'output': 'Quelle série de livres est la plus longue ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which member of BTS raps and speaks English fluently?',\n",
       "  'output': 'Quel membre de BTS rappe et parle en un anglais fluide ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many members are there in the United States Senate?',\n",
       "  'output': 'Combien de membres siègent au Sénat des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who was Fulvia's first husband?\",\n",
       "  'output': 'Qui était le premier mari de Fulvie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was John Adams the third president of the United States?',\n",
       "  'output': 'John Adams était-t-il le troisième président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the youngest person to win an Oscar for Best Director?',\n",
       "  'output': 'Qui est la plus jeune personne a avoir remporté l’Oscar du meilleur réalisateur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the last Back To The Future movie released?',\n",
       "  'output': 'En quelle année est sorti le dernier film Retour vers le futur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the second deepest lake in the world?',\n",
       "  'output': 'Quel est le deuxième lac au monde en termes de profondeur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is New York the capital city of the United States?',\n",
       "  'output': 'New York est-elle la capitale des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest mountain in Africa?',\n",
       "  'output': 'Quelle est la montagne la plus haute d’Afrique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first president of Russia?',\n",
       "  'output': 'Comment s’appelait le premier président de la Russie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What city was home to a school of classical music composers and the site of a 16th century Ottoman siege?',\n",
       "  'output': 'Quelle ville a été le siège d’une école de compositeurs de musique classique ainsi que le site du siège ottoman du 16e siècle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who were France's military in the Battle of Waterloo?\",\n",
       "  'output': 'Qui étaient les soldats français dans la Bataille de Waterloo ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the fifteenth president of the United States?',\n",
       "  'output': 'Qui était le 15e Président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the former U.S. Secretary of State and the First Lady of the United States to the 42nd president?',\n",
       "  'output': 'Quelle ancienne secrétaire d’État américaine a été la première dame du 42e président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third biggest island in Hawaii?',\n",
       "  'output': 'Quelle est la troisième plus grande île d’Hawaï ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the Portuguese player bought from Wolverhampton by Liverpool in 2020 and he was born on December 4, 1996?',\n",
       "  'output': 'Qui est le joueur portugais acheté à Wolverhampton par Liverpool en 2020 et qui est né le 4 décembre 1996 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third longest river in the world and the longest in China?',\n",
       "  'output': 'Quel est le troisième plus long fleuve du monde et le plus long de Chine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which is the poorest country in the world?',\n",
       "  'output': 'Quel est le pays le plus pauvre du monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the leader of military campaigns of the Mongol Empire at the turn of the thirteenth century?',\n",
       "  'output': 'Qui était le dirigeant des campagnes militaires de l’Empire mongol au tournant du treizième siècle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first disabled female United States senator?',\n",
       "  'output': 'Qui était la première femme handicapée à être élue sénatrice des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who had a longer reign, Cleopatra or King Tut?',\n",
       "  'output': 'Qui a eu le plus long règne : Cléopâtre ou le roi Tut ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Axis Power had atomic bombs dropped on it, Italy or Japan?',\n",
       "  'output': 'Quelle puissance de l’Axe a laché des bombes atomiques dessus l’Italie ou le Japon ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries in the United Kingdom?',\n",
       "  'output': 'Combien de pays le Royaume-Uni compte-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In what year did the first album of the Canadian band who made the song Tom Saywer come out?',\n",
       "  'output': 'En quelle année est sorti le premier album du groupe canadien qui a fait la chanson Tom Saywer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the 36th president of the United States?',\n",
       "  'output': 'Qui était le 36e président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which U.S. city has a lesser population, New York City or Chicago?',\n",
       "  'output': 'Quelle ville des États-Unis est la moins peuplée, New York ou Chicago ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which Wheel of Time novels were not completed before Robert Jordan's death?\",\n",
       "  'output': 'Quels romans de La roue du temps n’ont pas été achevés avant la mort de Robert Jordan ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which of the Great Lakes is not at all in Canada?',\n",
       "  'output': 'Parmi les Grands Lacs, lequel n’est absolument pas situé au Canada ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first president of the United States and also attacked the Hessian military base on Christmas Day?',\n",
       "  'output': 'Qui était le premier président des États-Unis et a aussi attaqué la base militaire de Hesse le jour de Noël ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which A Song of Ice and Fire book does not have plurals in its title?',\n",
       "  'output': 'Quel ouvrage de la série Le Trône de fer n’a pas de mot au pluriel dans son titre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is the author of Lord of the Flies a Nobel Prize winner?',\n",
       "  'output': 'L’auteur de Sa Majesté des mouches a-il remporté un prix Nobel ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which southern states did Trump not win in the 2016 Republican Party Primaries?',\n",
       "  'output': 'Quels sont les États du Sud que Trump n’a pas remportés lors des primaires du parti républicain en 2016 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who founded the city of Philadelphia?',\n",
       "  'output': 'Qui a fondé la ville de Philadelphie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What river flows through Germany and is the second longest river in Europe?',\n",
       "  'output': 'Quel fleuve traversant l’Allemagne est le deuxième plus long fleuve d’Europe ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the oldest university in Italy?',\n",
       "  'output': 'Quelle est la plus ancienne université d’Italie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the female member of the ice dancer pairs team who won the gold medal in the 2000 Olympics?',\n",
       "  'output': 'Qui est la membre féminine de l’équipe de danse sur glace en couple qui a remporté la médaille d’or aux Jeux Olympiques de 2000 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How many of Paul Horgan's books won a Pulitzer Prize?\",\n",
       "  'output': 'Combien de livres de Paul Horgan ont remporté un Prix Pulitzer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest lake in Germany?',\n",
       "  'output': 'Quel est le plus grand lac d’Allemagne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the Chinese civilization founded?',\n",
       "  'output': 'Quand a été fondée la civilisation chinoise ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What country in Asia co-led an alliance to eventually win the global conflict beginning in 1939?',\n",
       "  'output': 'Quel pays en Asie a codirigé une alliance afin de gagner éventuellement le conflit qui a débuté en 1939 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the king of England?',\n",
       "  'output': 'Qui est la reine d’Angleterre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which war lasted longer, the American Revolution or the French Revolution?',\n",
       "  'output': 'Quelle guerre a duré plus longtemps, la révolution Américaine ou la révolution française ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Brazil shares a border with every South American country except which two?',\n",
       "  'output': 'Le Brésil partage une frontière avec tous les pays d’Amérique du Sud, sauf deux. Lesquels ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the earliest known civilization?',\n",
       "  'output': 'Quelle était la première civilisation connue ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): How many Olympic medals does the US Women's Soccer Team have that aren't gold?\",\n",
       "  'output': 'Combien de médailles olympiques de l’équipe féminine de football des États-Unis ne sont pas en or ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Can you score a goal yourself in professional soccer?',\n",
       "  'output': 'Peut-on marquer un but contre son camps en football professionnel ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which movies did Alfred Hitchcock get nominated for Best Director and didn't win?\",\n",
       "  'output': 'Pour quels films Alfred Hitchock a-t-il été nominé dans la catégorie de Meilleur réalisateur, mais n’a pas gagné ce trophée ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the child of Queen Victoria and was married to Alexandra of Denmark?',\n",
       "  'output': 'Quel enfant de la reine Victoria a été marié à Alexandra du Danemark ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What United States president served during both The Great Depression and World War I?',\n",
       "  'output': 'Quel président des États-Unis était en fonction pendant la grande Dépression et la 1ère Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Star Wars trilogy movie had the highest budget?',\n",
       "  'output': 'Quel est le film de la trilogie Stars Wars avec le plus gros budget ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was prime minister of United Kingdom and defeated Napoleon at Waterloo?',\n",
       "  'output': 'Quel est le Premier ministre du Royaume-Uni qui a vaincu Napoléon à Waterloo ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): In 2019, who did not win the MLB World Series?',\n",
       "  'output': 'En 2019, quelle équipe n’a pas remporté la Série mondiale de la MLB ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which series has more books, The Wheel of Time or The Sword of Truth?',\n",
       "  'output': 'Quelle série comporte le plus de livres, La roue du temps ou l’Épée de la vérité ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which state has the United State's oldest bird as its official state bird?\",\n",
       "  'output': 'Quel est l’État dont l’oiseau le plus ancien des États-Unis est l’oiseau officiel ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the 19th president of the United States of America?',\n",
       "  'output': 'Qui était le dix-neuvième président des États-Unis d’Amérique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first prime minister of India?',\n",
       "  'output': 'Qui était le premier Premier Ministre de l’Inde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which member of One Direction was not born in England?',\n",
       "  'output': 'Quel membre de One Directions n’est pas né en Angleterre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which members of Blackpink were not born in South Korea?',\n",
       "  'output': 'Quelles membres des Blackpink ne sont pas nées en Corée du Sud ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the name of Ed Sheeran's first US number 1 single?\",\n",
       "  'output': 'Quel est le titre du premier single d’Ed Sheeran classé numéro 1 au États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which professional boxer has won the most fights?',\n",
       "  'output': 'Quel boxeur professionnel a gagné le plus de combats ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who has won fewer Academy Awards for Best Actor, Tom Hanks or Leonardo DiCaprio?',\n",
       "  'output': 'Qui a remporté le moins d’Oscar du meilleur acteur : Tom Hanks ou Leonardo DiCaprio ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest building in the capital of Russia?',\n",
       "  'output': 'Quel est l’édifice le plus haut de la capitale de la Russie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was president after the president who won the Battle of New Orleans in the War of 1812?',\n",
       "  'output': 'Quel président a succédé à celui qui a gagné la Bataille de la Nouvelle-Orléans pendant la Guerre de 1812 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Russia where hard bass music originated?',\n",
       "  'output': 'La Russie est-elle le pays d’origine de la musique hard bass ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest country by area?',\n",
       "  'output': 'Quel est le plus grand pays en termes de superficie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who won more medals, Italy or Belarus in the 2008 Summer Olympics?',\n",
       "  'output': 'Qui de l’Italie ou la Biélorussie a remporté le plus de médailles au jeux olympiques d’été de 2008 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Academy Awards has Helen Mirren won?',\n",
       "  'output': 'Combien d’Oscars du cinéma Helen Mirren a-t-elle remportés ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which 1952 Gene Kelly movie failed to earn a Best Picture nod at the Oscars that year?',\n",
       "  'output': 'Quel est le nom du film du réalisateur Gene Kelly, sorti en 1952 et qui n’a pas pu remporter l’Oscar du meilleur film la même année ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the population of Manila?',\n",
       "  'output': 'Combien d’habitants compte Manille ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which US city is nicknamed the Big Apple?',\n",
       "  'output': 'Quelle ville des États-Unis est surnommée La grosse pomme ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which Netflix series has been watched more, Tiger King or The Queen's Gambit?\",\n",
       "  'output': 'Quelle est la série Netflix la plus regardée : Au royaume des fauves ou Le jeu de la dame ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who played shooting guard and is part owner of the Charlotte Hornets?',\n",
       "  'output': 'Qui a joué en position d’arrière et possède une partie des Hornets de Charlotte ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Republican governors has North Carolina had since 1973?',\n",
       "  'output': 'Combien de gouverneurs républicains la Caroline du Nord a-t-elle eu depuis 1973 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries in South America are landlocked?',\n",
       "  'output': 'Combien de pays enclavés l’Amérique du Sud compte-t-elle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state is the largest in area and hosts the highest mountain in the U.S.?',\n",
       "  'output': 'Quel État est le plus grand en superficie et abrite la plus haute montagne des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the first eruption of Mount Saint Helens?',\n",
       "  'output': 'Quand a eu lieu la première éruption du Mont Saint Helens ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Lawrence of Arabia actor was nominated for Best Actor but did not win?',\n",
       "  'output': 'Lequel des acteurs du film Lawrence d’Arabie a été nominé pour l’Oscar du meilleur acteur, mais ne l’a pas remporté ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Canberra the capital city of Australia?',\n",
       "  'output': 'Canberra est-elle la capitale de l’Australie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Athens the capital of the state of Georgia?',\n",
       "  'output': 'Athènes est-elle la capitale de l’État de Géorgie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Harry Potter character was the Headmaster of Hogwarts School of Witchcraft and Wizardry and was killed by Severus Snape?',\n",
       "  'output': 'Quel personnage de Harry Potter était directeur de l’école des sorciers Poodlard, tué par Severus Snape ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is the first Call of Duty game centered around WW I?',\n",
       "  'output': 'Est-ce que le premier jeu Call of Duty est centré autour de la première guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did the first Fifty Shades of Grey book come out?',\n",
       "  'output': 'Quand a été publié le premier livre Cinquante nuances de Grey ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest man-made monument in the United States?',\n",
       "  'output': 'Quel est le plus grand monument créé par les hommes aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which ship did the author of the Origin of Species travel aboard in 1859?',\n",
       "  'output': 'Dans quel bateau a voyagé l’auteur de L’origine des espèces en 1859 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the shortest battle in World War II?',\n",
       "  'output': 'Quelle est la bataille la plus courte pendant la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the tallest member of the Jonas Brothers?',\n",
       "  'output': 'Quel membre du groupe Jonas Brother est le plus grand ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did George Washington win his first presidency of the United States?',\n",
       "  'output': 'Quand est-ce que George Washington a remporté sa première élection présidentielle des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the population of New York City?',\n",
       "  'output': 'Combien d’habitants compte New York, NY ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old is the current head coach of the Seattle Seahawks?',\n",
       "  'output': 'Quel âge l’actuel entraîneur titulaire des Seahawks de Seattle a-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does Cujo have more pages than Pet Sematary?',\n",
       "  'output': 'Cujo comporte-t-il plus de pages que Simetierre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was a US president and involved in the Watergate scandal?',\n",
       "  'output': 'Quel président américain a été impliqué dans le scandale du Watergate ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the deadliest volcanic eruption?',\n",
       "  'output': 'Quelle était l’éruption volcanique la plus mortelle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Pride and Prejudice written before or after Sense and Sensibility?',\n",
       "  'output': 'Orgueil et préjugés a-t-il été écrit avant ou après Raison et sensibilité ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did the author who wrote To Kill a Mockingbird die?',\n",
       "  'output': 'Quand l’auteur du livre Ne tirez pas sur l’oiseau moqueur est-il décédé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the shortest river in feet in Brazil?',\n",
       "  'output': 'Quelle est la plus courte rivière (en mètres) du Brésil ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year was the first official MLB World Series played?',\n",
       "  'output': 'En quelle année s’est jouée la première Série mondiale de la MLB ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did It or Pet Sematary have better sales?',\n",
       "  'output': 'A-t-il obtenu plus de vente que Simetierre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was born and raised in Hyde Park, New York and was elected to multiple terms in the United States presidency?',\n",
       "  'output': 'Quel président, plusieurs fois élu à la tête des États-Unis, est né et a grandi à Hyde Park, dans l’État de New York ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Is Xi'an the oldest city in China?\",\n",
       "  'output': 'Xi’an est-elle la ville plus ancienne de Chine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which British monarch from the House of Hanover was not male?',\n",
       "  'output': 'Quel roi britannique de la Maison de Hanovre n’était pas de sexe masculin ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the current prime minister of Bahrain?',\n",
       "  'output': 'Qui est le Premier Ministre actuel de Bahreïn ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the first book in Stephen King's Dark Tower series?\",\n",
       "  'output': 'Quel est le premier livre de la série La Tour sombre de Stephen King ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the head coach for the Kansas City Chiefs in 2020?',\n",
       "  'output': 'Qui était l’entraîneur titulaire des Chiefs de Kansas City en deux mille vingt ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did Pokemon Ruby and Sapphire come out?',\n",
       "  'output': 'Quand est sorti Pokémon Rubis et Saphir ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Tiger Woods or Jordan Spieth younger when winning the gold masters?',\n",
       "  'output': 'Qui de Tiger Wood ou de Jordan Spieth était le plus jeune quand il a remportaient les Masters de Golf ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many World Cup Football Championships has Brazil won?',\n",
       "  'output': 'Combien de Coupes du monde de football le Brésil a-t-il remportées ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Olympic medals does Usain Bolt have that are not gold?',\n",
       "  'output': 'Combien Usain Bolt a-t-il remporté de médailles olympiques autres que l’or ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the name of the last Pokémon core video game that was released?',\n",
       "  'output': 'Quel est le nom du dernier jeu vidéo Pokemon core qui est paru ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state that starts with \"O\" is not west of the Mississippi River?',\n",
       "  'output': 'Quel État commençant par O n’est pas à l’ouest du fleuve Mississippi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does the cherry come before the strawberry in Pac-Man?',\n",
       "  'output': 'La Cerise vient-elle avant la Fraise dans Pacman ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was a Pharaoh of the 18th Dynasty and had no successor?',\n",
       "  'output': 'Quel était le pharaon de la 18e dynastie sans successeur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Has Mount Fuji erupted before 1707?',\n",
       "  'output': 'Le Mont Fuji est-il entré en éruption avant 1707 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What was the first Assassin's Creed game to introduce the character Layla Hassan?\",\n",
       "  'output': 'Quel a été le premier jeu Assassin’s Creed à introduire le personnage Layla Hassan ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the second book in Stephen King's Dark Tower series?\",\n",
       "  'output': 'Quel est le titre du deuxième livre de la série La Tour sombre de Stephen King ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Where is the oldest body of water that is not an ocean?',\n",
       "  'output': 'Quelle est la plus ancienne étendue d’eau qui n’est pas un océan ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Athelstan the first king of England?',\n",
       "  'output': 'Athelstan était-il le premier roi de l’Angleterre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old is the current head coach of the Philadelphia Eagles?',\n",
       "  'output': 'Quel âge a l’actuel entraîneur en chef des Eagles de Philadelphie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first queen of Hawaii?',\n",
       "  'output': 'Qui était la première reine de Hawaï ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who did Keanu Reeves play in the movie The Matrix?',\n",
       "  'output': 'Quel personnage Keanu Reeves incarne-t-il dans le film Matrix ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which river is longer than the Mississippi River?',\n",
       "  'output': 'Quel fleuve est plus long que le Mississippi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Alix Klineman win a medal at the 2021 Olympics?',\n",
       "  'output': 'Alix Klineman a-t-elle gagné une médaille aux Jeux Olympiques de 2021 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the population of the largest country by size in the world?',\n",
       "  'output': 'Quelle est la population du plus grand pays du monde par sa taille ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the second book in the Lord of the Rings trilogy by J.R.R. Tolkien?',\n",
       "  'output': 'Quel est le deuxième livre de la trilogie Le Seigneur des anneaux de J.R.R. Tolkien ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many co-princes does Andorra have?',\n",
       "  'output': 'Combien de co-princes y a-t-il en Andorre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What famous general was exiled to the island of Elba and later St Helena?',\n",
       "  'output': 'Quel célèbre général a été exilé sur l’île d’Elbe, et plus tard sur l’île Sainte-Hélène ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Roman Emperor led from 198 to 217 but never had children?',\n",
       "  'output': 'Quel empereur romain qui a dirigé entre 198 et 217 mais n’a jamais eu d’enfants ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many kids does the star of The Terminal have?',\n",
       "  'output': 'De combien de fils et filles est-il père, l’acteur vedette du film Le Terminal ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What hip hop trio was Snoop Dogg in?',\n",
       "  'output': 'De quel trio de hip-hop Snoop Dog faisait-il partie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many books are in the Dark Tower series?',\n",
       "  'output': 'Combien de tomes compte la série La Tour sombre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Thomas Jefferson the 2nd U.S. president?',\n",
       "  'output': 'Thomas Jefferson était-il le deuxième président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who won a Grammy for best Reggae album in 1995 five with Boombastic?',\n",
       "  'output': 'Qui a remporté un Grammy Award du meilleur album de reggae en mille neuf cent quatre-vingt-quinze avec le morceau Boombastic ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does Germany border 9 other countries?',\n",
       "  'output': 'L’Allemagne partage t-elle une frontière avec 9 autres pays ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old is the current coach of Boston Celtics?',\n",
       "  'output': 'Quel âge a l’entraîneur actuel des Celtics de Boston ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Where is the Temple of the Tooth found?',\n",
       "  'output': 'Où se trouve le Temple de la Dent ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was the fourth queen of England when she died?',\n",
       "  'output': 'Quel âge avait la quatrième reine d’Angleterre à sa mort ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What book series has sold the most?',\n",
       "  'output': 'Quelle série de livres a été la plus vendue ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who played Gandalf in Lord of the Rings?',\n",
       "  'output': 'Qui a joué Gandalf dans Le Seigneur des anneaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which movie made the most money in the United States in 1980?',\n",
       "  'output': 'Aux États-Unis, quel film a le plus rapporté en 1980 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the largest city in the state of North Dakota?',\n",
       "  'output': 'Quelle est la plus grand ville de l’État du Dakota du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first United States president?',\n",
       "  'output': 'Qui était le premier Président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Tokyo the capital of China?',\n",
       "  'output': 'Tokyo est-elle la capitale de la Chine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the wife of the 42nd president of the United States?',\n",
       "  'output': 'Qui était la femme du 42e président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the author of The Adventures of Huckleberry Finn born?',\n",
       "  'output': 'Quand est né l’auteur des Aventures de Huckleberry Finn ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does Fifty Shades have others books in its series?',\n",
       "  'output': 'La série Cinquante Nuances de Grey comporte-t-elle d’autres livres ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the fourth tallest mountain in Asia?',\n",
       "  'output': 'Quelle est la quatrième montagne la plus haute d’Asie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who ran for vice presidency in 2020 and attended Howard University?',\n",
       "  'output': 'Qui s’est présenté à la vice-présidence en 2020 et a fréquenté l’université Howard ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many times did Robert Frost win the Pulitzer award?',\n",
       "  'output': 'Combien de fois Robert Frost a-t-il remporté le Prix Pulitzer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What battle in the Pacific during WWII saw the most American soldiers killed?',\n",
       "  'output': 'Quelle bataille dans le Pacifique pendant la Seconde Guerre mondiale a coûté la vie au plus grand nombre de soldats américains ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the wife of the 44th president of the United States who was also the first Black American president?',\n",
       "  'output': 'Qui est la femme du 44e Président de États-Unis, qui est également le premier Président noir américain ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Stephen King write Creepshow or Firestarter first?',\n",
       "  'output': 'Lequel de Creepshow et de Charlie Stephen King a-t-il écrit en premier ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What kind of government does China have?',\n",
       "  'output': 'Quel type de gouvernement la Chine possède-t-elle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was built first, the Erie Canal or the Trans-Continental Railroad?',\n",
       "  'output': 'Qu’est-ce qui a été construit en premier, le canal Érié ou le Chemin de fer National Transcontinental ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Did Assassin's Creed come out before 2008?\",\n",
       "  'output': 'Assassins Creed est-il sorti avant 2008 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the awards for sci-fi horror and fantasy movies called?',\n",
       "  'output': 'Comment appelle-t-on le prix qui récompense les films de science-fiction, d’horreur et les films fantastiques ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Are there more than fifty United States senators?',\n",
       "  'output': 'Y a-t-il plus de cinquante sénateurs aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many books hold world records data?',\n",
       "  'output': 'Combien de livres contiennent des données sur les records mondiaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the City of Brotherly Love?',\n",
       "  'output': 'Quelle est la Ville de l’amour fraternel ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first person to reach the summit of Mt. Everest?',\n",
       "  'output': 'Comment s’appelle la personne qui a atteint pour la première fois le sommet du mont Everest ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did the Roman Empire fall?',\n",
       "  'output': 'Quand a eu lieu la chute de l’Empire romain ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the capital city of the country where the Eiffel Tower is?',\n",
       "  'output': 'Quel est le nom de la capitale du pays où se trouve la tour Eiffel ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Inception have a bigger budget than Dunkirk?',\n",
       "  'output': 'Inception a-t-il eu un budget plus important que celui de Dunkerque ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first owner of the Jacksonville Jaguars?',\n",
       "  'output': 'Qui a été le premier propriétaire des Jaguars de Jacksonville ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the military leader of the country that attacked the United States in 1941?',\n",
       "  'output': 'Qui était le leader militaire du pays qui a attaqué les États Unis en 1941 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Have the Tamps Bay Buccaneers or Dallas Cowboys earned more Super Bowl victories?',\n",
       "  'output': 'Qui des Buccaneers de Tampa Bay ou des Cowboys de Dallas a remporté le plus de Super Bowls ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which series has more books, Stalking Jack the Ripper or Lord of the Rings?',\n",
       "  'output': 'Quelle série comporte le plus de livres, Jack l’Éventreur ou Le Seigneur des anneaux ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is South America the largest country?',\n",
       "  'output': 'L’Amérique du Sud est-il le plus grand pays ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which country has a larger population, Canada or Mexico?',\n",
       "  'output': 'Quel pays est le plus peuplé, le Canada ou le Mexique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which movie starred Roger Moore and was set mostly in Louisiana?',\n",
       "  'output': 'Quel film figure Roger Moore et se déroule principalement en Louisiane ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Has there ever been a woman U.S. president?',\n",
       "  'output': 'Y a t-il déjà eu une présidente aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who caused Harry many problems while trying to help him in his second year at Hogwarts?',\n",
       "  'output': 'Qui a créé beaucoup de problèmes à Harry en essayant de l’aider durant sa deuxième année à Poudlard ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the general who lead his forces in the Battle of Antietam, but did not win the battle?',\n",
       "  'output': 'Qui était le général qui a mené ses forces dans la bataille de Sharpsburg mais l’a perdu ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which countries in continental Europe are not currently in the European Union?',\n",
       "  'output': 'Quels pays d’Europe continentale ne font actuellement pas partie de l’Union européenne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Has the United States ever had a non-white president?',\n",
       "  'output': 'Les États-Unis ont-ils déjà eu un président qui n’est pas de race blanche ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many competitors were in the Triwizard Tournament of 1994?',\n",
       "  'output': 'Combien de concurrents ont participé au Tournoi des Trois Sorciers en 1994 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which song has the most words in it?',\n",
       "  'output': 'Quelle chanson est composée du plus grand nombre de mots ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was first elected to the U.S. Senate in 1984 and became Senate Majority Leader in 2014?',\n",
       "  'output': 'Quel membre du Sénat des États-Unis, élu pour la première fois en 1984, est devenu chef de la majorité au Sénat en 2014 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Harry Potter and the Deathly Hallows split into 2 movies?',\n",
       "  'output': 'Harry Potter et les reliques de la mort a-t-il été divisé en deux films ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Pope Francis the first South American pope?',\n",
       "  'output': 'Le pape François est-il le premier pape originaire de l’Amérique du Sud ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many countries border the equator?',\n",
       "  'output': 'Combien de pays bordent l’Équateur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was a wife of Edward I of England and was a daughter of Philip III of France?',\n",
       "  'output': 'Quelle femme d’Édouard Ier d’Angleterre était une fille de Philippe III de France ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who built the pyramids in Mexico?',\n",
       "  'output': 'Qui a construit les pyramides au Mexique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who was Princess Peach's cousin?\",\n",
       "  'output': 'Qui était le cousin de Princesse Peach ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many video games have more than 60,000,000 sales?',\n",
       "  'output': 'Combien de jeux vidéo ont dépassé les 60 000 000 de ventes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which colony became the first state in the US?',\n",
       "  'output': 'Quelle colonie est devenue le premier état aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old was Joe Biden by the time he was elected the president of the United States?',\n",
       "  'output': 'Quel âge avait Joe Biden lorsqu’il a été élu Président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Johnny Depp the main character in The Matrix?',\n",
       "  'output': 'Johnny Depp était-il le personnage principal de The Matix ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many world leaders were part of the Yalta Conference?',\n",
       "  'output': 'Combien de dirigeants du monde se sont réunis à la conférence de Yalta ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the oldest parliament in world history established?',\n",
       "  'output': 'Quand est-ce que le plus ancien parlement de l’histoire du monde a été créé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is a Serbian professional tennis player who did not win the gold medal at the 2008 Beijing Olympics?',\n",
       "  'output': 'Comment s’appelle un joueur de tennis professionnel serbe qui n’a pas réussi à remporter la médaille d’or aux Jeux Olympiques de Pékin 2008 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was the Kingdom of Sardinia a party to the Treaty of Worms?',\n",
       "  'output': 'Le Royaume de la Sardaigne était-il signataire du traité de Worms ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which of the Great Lakes do not share a border with Ohio?',\n",
       "  'output': 'Lequel des Grands Lacs n’est pas limitrophe de l’Ohio ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the name of the first astronaut that did not survive the space mission?',\n",
       "  'output': 'Quel était le nom du premier astronaute qui n’avait pas survécu à la mission spatiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did the Confederate States win the Civil War?',\n",
       "  'output': 'Les États confédérés d’Amérique ont-ils remporté la guerre de Sécession ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was the Soviet Union an American ally during World War ll?',\n",
       "  'output': 'L’Union soviétique était-elle un allié des États-Unis pendant la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Harry Potter take place in England?',\n",
       "  'output': 'Harry Potter se déroule-t-il en Angleterre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the lowest point in Asia?',\n",
       "  'output': 'Quelle est la région la plus basse d’Asie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Rowan Atkins make an appearance in Jaws?',\n",
       "  'output': 'Rowan Atkins a-t-il fait une apparition dans Les dents de la mer ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many oceans border Russia?',\n",
       "  'output': 'Combien d’océans bordent la Russie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): The first United States president to be born in the 20th century was a Lieutenant in which branch of the United States military?',\n",
       "  'output': 'Le premier président des États-Unis à être né au 20e siècle était un lieutenant dans quelle branche de l’armée américaine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first female pilot to fly across the Atlantic ocean?',\n",
       "  'output': 'Qui a été la première pilote féminine à traverser l’Océan Atlantique par voie aérienne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the sickest city in the world?',\n",
       "  'output': 'Quelle est la ville la plus malade du monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the video game with the second highest sales?',\n",
       "  'output': 'Quel est le jeu vidéo qui enregistre les deuxièmes meilleures ventes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the smallest country in the world by land mass?',\n",
       "  'output': 'Quel est le plus petit pays au monde en termes de superficie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first female pilot to cross the Atlantic Ocean?',\n",
       "  'output': 'Qui était la première femme pilote à traverser l’Océan Atlantique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year did the Philadelphia Phillies win their first World Series?',\n",
       "  'output': 'En quelle année les Philadelphia Phillies ont-ils remporté leur première Série mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who is the singer in Blackpink who was born in Thailand?',\n",
       "  'output': 'Quelle chanteuse de Blackpink est-elle née en Thaïlande ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Who's the 3rd president of the United States?\",\n",
       "  'output': 'Qui a été le 3e président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which side won World War II, the Axis or the Allies?',\n",
       "  'output': 'Quel camp a gagné la Seconde Guerre mondiale, l’Axe ou les Alliés ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What movie was directed by Peter Jackson and won the Academy Award for Best Picture?',\n",
       "  'output': 'Quel film a été réalisé par Peter Jackson et a remporté l’Oscar du meilleur film ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which city is not on only one continent?',\n",
       "  'output': 'Quelle ville n’est pas sur un seul continent ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What country was part of the Allied Powers and the location of D-Day?',\n",
       "  'output': 'Dans quel pays faisant partie des puissances Alliés s’est déroulé le Jour J ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many children did Cleopatra have?',\n",
       "  'output': 'Combien d’enfants Cléopâtre avait-elle ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Of Mice and Men come out before 1915?',\n",
       "  'output': 'Des souris et des hommes est-il sorti avant 1915 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which was released later, Gauntlet: Legends or Gauntlet: Dark Legacy?',\n",
       "  'output': 'Quel titre est sorti le plus tard, Gauntlet : Legend ou Gauntlet : Dark Legacy ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When did the author who wrote Don Quixote die?',\n",
       "  'output': 'Quand l’auteur de Don Quichotte est-il décédé ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): Which game in the Assassin's Creed series takes place in the time of the Vikings?\",\n",
       "  'output': 'Quel jeu de la série Assassins Creed se déroule à l’époque des Vikings ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What mountain in the Himalayas is the fourth tallest in the world?',\n",
       "  'output': 'Quelle montagne de la chaîne de l’Himalaya est le quatrième sommet le plus élevé au monde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Punic wars have been fought?',\n",
       "  'output': 'Combien de Guerres puniques ont-elles été menées ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What is the lowest point on the Earth's surface?\",\n",
       "  'output': 'Quel est le point le plus bas de la surface de la Terre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did The English Patient win an Oscar for Best Picture?',\n",
       "  'output': 'Le Patient anglais a-t-il gagné un Oscar du meilleur film ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Dark Tower series are there?',\n",
       "  'output': 'Combien y a-t-il de séries de La Tour sombre ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Denali taller than Mount Whitney?',\n",
       "  'output': 'Le Denali est-il plus haut que le Mont Whitney ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first governor of the state of New York?',\n",
       "  'output': 'Qui a été le premier gouverneur de l’État de New York ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the third Fast & Furious movie to be released?',\n",
       "  'output': 'Quel est le troisième film de la série Fast and Furious à être sorti ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the first movie to win an Oscar for Best Animated Feature?',\n",
       "  'output': 'Quel était le premier film à remporter un Oscar du meilleur film d’animation ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was For Whom the Bell Tolls published before 1930?',\n",
       "  'output': 'Pour qui sonne le glas a-t-il été publié avant 1930 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the sixth tallest mountain in North America?',\n",
       "  'output': 'Quelle est la sixième plus haute montagne d’Amérique du Nord ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest building in the capital city of Spain?',\n",
       "  'output': 'Quel est le bâtiment le plus élevé dans la capitale d’Espagne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Japan invade Korea before King Gojong died?',\n",
       "  'output': 'Le Japon a-t-il envahi la Corée avant le décès du roi Gojong ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the last year the Philadelphia Flyers won a Stanley Cup?',\n",
       "  'output': 'Quand les Flyers de Philadelphie ont-ils gagné la Coupe Stanley pour la dernière fois ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was John Quincy Adams the fifth president of the United States of America?',\n",
       "  'output': 'John Quincy Adams était-il le cinquième président des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the 2nd lowest place below sea level in the United States?',\n",
       "  'output': 'Quel est le 2e point le plus bas en dessous du niveau de la mer aux États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the political party of President Cyril Ramaphosa of South Africa?',\n",
       "  'output': 'Quel est le parti politique de Cyril Ramaphosa, le Président de l’Afrique du Sud ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Santiago the capital of Chile?',\n",
       "  'output': 'Santiago est-elle la capitale du Chili ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many books are in the Hand of Thrawn series?',\n",
       "  'output': 'Combien de livres figurent dans la série La Main de Thrawn ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the Greek king of Macedon that conquered most parts of Asia and North Africa and had a sister called Cleopatra of Macedon?',\n",
       "  'output': 'Qui était le Grec de Macédoine qui a conquis la plupart de l’Asie et de l’Afrique du nord, et avait une sœur dénommée Cléopâtre de Macédoine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which is the second tallest mountain in Asia?',\n",
       "  'output': 'Quelle est la deuxième plus haute montagne d’Asie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the first pope?',\n",
       "  'output': 'Qui était le premier pape ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many total casualties were caused by World War II?',\n",
       "  'output': 'Quel est le bilan total de la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): What was B. B. King's guitar's name?\",\n",
       "  'output': 'Comment s’appelait la guitare de B.B. King ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was a senator from California and died in office in 1964?',\n",
       "  'output': 'Qui était un sénateur de Californie et est mort en fonction en 1964 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which state borders New Mexico and has the most populous capital city in the U.S.?',\n",
       "  'output': 'Quel État est limitrophe du Nouveau-Mexique et abrite la capitale la plus peuplée des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What year was the war between Egypt and Israel?',\n",
       "  'output': 'En quelle année s’est déroulée la guerre entre l’Égypte et Israël ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did Jack the Ripper get married?',\n",
       "  'output': 'Jack l’Éventreur s’est-il marié ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the second longest river in Brazil?',\n",
       "  'output': 'Quel est le deuxième plus long fleuve du Brésil ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the third largest mountain in the United States?',\n",
       "  'output': 'Quelle est la troisième plus grande montagne des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who plays for the Philadelphia 76ers and was born in Lagos, Nigeria?',\n",
       "  'output': 'Qui joue pour les 76ers de Philadelphie et est né à Lagos, au Nigeria ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What movie won the Oscar for Best Film in 2010?',\n",
       "  'output': 'Quel film a remporté l’Oscar du meilleur film en deux mille dix ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Brazil a democracy?',\n",
       "  'output': 'Le Brésil est-il un pays démocratique ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which oceans do not border Malaysia?',\n",
       "  'output': 'Quels océans ne bordent pas la Malaisie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Nero the fourth emperor of Rome?',\n",
       "  'output': 'Néron a-t-il été le quatrième empereur de Rome ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Was Otto von Bismarck the first Chancellor of Germany?',\n",
       "  'output': 'Otto von Bismarck était-il le premier chancelier d’Allemagne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many main islands does Japan have?',\n",
       "  'output': 'Combien d’îles compte le Japon ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What city is nicknamed the City of Angels?',\n",
       "  'output': 'Quelle ville est surnommée la Cité des anges ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the coach when Michael Jordan played for the Chicago Bulls?',\n",
       "  'output': 'Qui était entraîneur lorsque Michael Jordan jouait pour les Bulls de Chicago ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many counties are in Pennsylvania?',\n",
       "  'output': 'Combien de comtés y a-t-il en Pennsylvanie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was prime minister of the United Kingdom during most of World War II?',\n",
       "  'output': 'Qui était Premier ministre du Royaume-Uni pendant la majeure partie de la Seconde Guerre mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What country was part of the Allied Powers and was invaded by Germany?',\n",
       "  'output': 'Quel pays faisait partie des puissances Alliées et a été envahi par l’Allemagne ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Does Mexico City have a higher population than Tokyo?',\n",
       "  'output': 'Y a-t-il plus d’habitants dans le ville de Mexico qu’à Tokyo ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Winnie the Pooh a lion?',\n",
       "  'output': 'Winnie l’ourson est-il un lion ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is JK Rowling older than Margaret Atwood?',\n",
       "  'output': 'J.K. Rowling est-elle plus âgée que Margaret Atwood ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How old is the current president of basketball operations of the Philadelphia 76ers?',\n",
       "  'output': 'Quel âge l’actuel Président des opérations de basketball des 76ers de Philadelphie a-t-il ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which golfer has won the most green jackets?',\n",
       "  'output': 'Quel golfeur a remporté le plus de green jackets ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many movies are there in the Pirates of the Caribbean movie series?',\n",
       "  'output': 'Combien de films y a-t-il dans la série de films Pirates des Caraïbes ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who was the president of Argentina from 1989 to 1999?',\n",
       "  'output': 'Qui était le Président de l’Argentine, de mille neuf cent quatre-vingt-neuf à mille neuf cent quatre-vingt-dix-neuf ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is Texas the largest state in the U.S.?',\n",
       "  'output': 'Le Texas est-il le plus grand État des États-Unis ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many athletes who have competed in the Olympics have held political office?',\n",
       "  'output': 'Combien d’athlètes ayant participé aux Jeux olympiques ont occupé des fonctions politiques ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): When was Nelson's Column built?\",\n",
       "  'output': 'Quand la colonne Nelson a-t-elle été construite ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which NHL team is based in California and used to have Wayne Gretzky?',\n",
       "  'output': 'Quelle équipe de NHL est implanée en Californie et avait Wayne Gretzky dans ses rangs ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which NFL player currently plays for the Tampa Bay Buccaneers and was born in San Mateo, California?',\n",
       "  'output': 'Quel joueur de la NFL jouant actuellement pour les Buccaneers de Tampa Bay est né à San Mateo en Californie ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which mountains are higher, the Andes or the Himalayas?',\n",
       "  'output': 'Quelles sont les montagnes les plus hautes, les Andes ou l’Himalaya ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Is the governor of Michigan a democrat?',\n",
       "  'output': 'Le gouverneur du Michigan est-il membre du parti démocrate ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): When was the author that wrote Star Wars: Dark Force Rising born?',\n",
       "  'output': 'Quand est né l’auteur de Star Wars : La Bataille des Jedi ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What is the tallest mountain in India?',\n",
       "  'output': 'Quelle est la plus haute montagne d’Inde ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': \"Entity translate (EN→FR): In what year did Virginia win its first NCAA Division 1 Men's Basketball Championship?\",\n",
       "  'output': 'En quelle année la Virginie a-t-elle remporté son premier championnat NCAA de première division de basketball masculin ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Who built the first successful airplane?',\n",
       "  'output': 'Comment s’appelle le constructeur du premier avion à succès ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Did George R.R. Martin finish ASOIAF as of 2021?',\n",
       "  'output': 'George R.R. Martin a-t-il terminé Le Trône de fer en 2021 ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many Americans are estimated to have died during the Civil War?',\n",
       "  'output': 'à combien estime-t-on le nombre d’américains morts pendant la Guerre de Sécession ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which Republican primaries did George HW Bush run in, but not win as president?',\n",
       "  'output': 'À quelles primaires présidentielles du parti républicain George H. W. Bush s’est-il présenté, mais n’a pas gagné ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): How many representatives does California have in the House of Representatives?',\n",
       "  'output': 'Combien de Représentants la Californie compte-t-elle à la Chambre des Représentants ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Are citizens able to vote in Cambodia?',\n",
       "  'output': 'Les citoyens peuvent-ils voter au Cambodge ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): Which author has won the most Newbery Awards?',\n",
       "  'output': 'Quel auteur a remporté le plus de Médailles Newbery ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the bloodiest battle of World War 2?',\n",
       "  'output': 'Quelle fut la bataille la plus sanglante de la Seconde Guerre Mondiale ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What was the last championship won by Lionel Messi for Argentina?',\n",
       "  'output': 'Quel est le dernier championnat que Lionel Messi a remporté avec l’Argentine ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What player for the Los Angeles Angels is both a pitcher and an MVP batter?',\n",
       "  'output': 'Quel est le joueur des Angels de Los Angeles qui est à la fois lanceur et batteur ?'},\n",
       " {'task': 'Entity-aware MT',\n",
       "  'input': 'Entity translate (EN→FR): What movie came out in 2018 and starred Malin Åkerman?',\n",
       "  'output': 'Quel film sorti en 2018 avait pour vedette Malin Akerman ?'},\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_test = os.path.join(os.getcwd(),r\"data\\test_data.json\")\n",
    "load_preprocess_test(data_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86d47a-e927-4694-9464-f3229e59e3ff",
   "metadata": {},
   "source": [
    "### Loading Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a75c613b-1a79-43b4-817e-66f74df75019",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "77f7cd80-e16f-481e-bc73-3ceacea5a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c6f22-41f4-42c4-99f8-8a047b2ab153",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88ba6106-6b17-42a9-9d90-44432e726a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(samples):\n",
    "    # Tokenize inputs and targets\n",
    "    inputs = tokenizer(samples[\"input\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    targets = tokenizer(samples[\"output\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    inputs = {key: torch.tensor(value).to(device) for key, value in inputs.items()}\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f455b5b6-4549-45a4-826c-cb4f697b1fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(),r\"data\\train_data.json\")\n",
    "train_data = load_preprocess_train(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "062acc4b-b4f4-4334-b0dd-e5a915761bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f44f5f49e54c7095691f209dbcca35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mmap(preprocess_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForSeq2Seq(tokenizer, model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Byom\\Lib\\site-packages\\datasets\\arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    555\u001b[0m }\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    558\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Byom\\Lib\\site-packages\\datasets\\arrow_dataset.py:3074\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3070\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3071\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3072\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3073\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3074\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3075\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3076\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Byom\\Lib\\site-packages\\datasets\\arrow_dataset.py:3516\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3515\u001b[0m     _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 3516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m iter_outputs(shard_iterable):\n\u001b[0;32m   3517\u001b[0m         num_examples_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(i)\n\u001b[0;32m   3518\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m update_data:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Byom\\Lib\\site-packages\\datasets\\arrow_dataset.py:3466\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[1;34m(shard_iterable)\u001b[0m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3465\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3466\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i, apply_function(example, i, offset\u001b[38;5;241m=\u001b[39moffset)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Byom\\Lib\\site-packages\\datasets\\arrow_dataset.py:3389\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[1;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[0;32m   3387\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[0;32m   3388\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[38;5;241m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m-> 3389\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mpreprocess_function\u001b[1;34m(samples)\u001b[0m\n\u001b[0;32m      4\u001b[0m targets \u001b[38;5;241m=\u001b[39m tokenizer(samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m      5\u001b[0m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m targets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {key: torch\u001b[38;5;241m.\u001b[39mtensor(value)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = train_data.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08da4b-127a-419f-9c24-78efb149c7e3",
   "metadata": {},
   "source": [
    "### Custom Loss function (Prioritizing Translation over NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d3341fda-619f-4249-bc9b-d060eeb3eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"Custom loss function to prioritize translation over NER.\"\"\"\n",
    "        labels = inputs.pop(\"labels\")  # Extract target labels\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  # Get logits\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1), ignore_index=-100)\n",
    "        ner_weight = 0.4\n",
    "        translation_weight = 0.6\n",
    "        task_type = inputs.get(\"task_type\", [\"Translation\"] * logits.shape[0])\n",
    "        task_weights = torch.tensor(\n",
    "            [ner_weight if \"NER\" in task else translation_weight for task in task_type],\n",
    "            device=logits.device,\n",
    "            dtype=torch.float,\n",
    "        )\n",
    "        weighted_loss = loss * task_weights.mean()\n",
    "        return (weighted_loss, outputs) if return_outputs else weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764bbe38-d29b-4d81-9986-96b33ef80c88",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "74b4df30-5fb1-4045-b0c6-a70c1ebd20ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_16824\\3224022601.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48400' max='48400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48400/48400 6:52:05, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.413900</td>\n",
       "      <td>0.035930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.022345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.015476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.010815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.008124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.006235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.004777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.003702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.002936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.002543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.002207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.001699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SafetensorError",
     "evalue": "Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"The requested operation cannot be performed on a file with a user-mapped section open.\" })",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 25\u001b[0m\n\u001b[0;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 25\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n\u001b[0;32m     26\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\modeling_utils.py:3032\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[1;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[0;32m   3027\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m   3029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[0;32m   3030\u001b[0m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[0;32m   3031\u001b[0m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[1;32m-> 3032\u001b[0m     safe_save_file(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file), metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m   3033\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3034\u001b[0m     save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Byom\\Lib\\site-packages\\safetensors\\torch.py:286\u001b[0m, in \u001b[0;36msave_file\u001b[1;34m(tensors, filename, metadata)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[0;32m    256\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[0;32m    257\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    258\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     serialize_file(_flatten(tensors), filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "\u001b[1;31mSafetensorError\u001b[0m: Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"The requested operation cannot be performed on a file with a user-mapped section open.\" })"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c5b8b4ff-10d0-4fbd-9fd2-6ca5fb08ecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to D:\\Byom (Don't Delete)\\LRNLP-updated-clean-21-04\\tf_base_finetuned\n"
     ]
    }
   ],
   "source": [
    "output_dir =  os.path.join(os.getcwd(),r\"tf_base_finetuned\")\n",
    "model.save_pretrained(output_dir, safe_serialization=False)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05699e91-711c-4562-8587-3a7e05c6d9fc",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3405bb65-55ea-46a7-ad79-62970f491f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_test = os.path.join(os.getcwd(),r\"data\\test_data.json\")\n",
    "test_data = load_preprocess_test(data_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0cf1a18-87d4-4f1d-aa45-2d10bbcdcc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_data(test_data,tokenizer):\n",
    "    bleu = evaluate.load(\"sacrebleu\")\n",
    "    sources,predictions, references = [],[],[]\n",
    "    for sample in tqdm(test_data, desc=\"Evaluating Translations\"):\n",
    "        input_text = sample[\"input\"]\n",
    "        sources.append(input_text[26:])\n",
    "        expected_output = sample[\"output\"]\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()} \n",
    "        outputs = model.generate(**inputs)\n",
    "        decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        predictions.append(decoded_output)\n",
    "        references.append([expected_output])  \n",
    "    bleu_score = bleu.compute(predictions=predictions, references=references)\n",
    "    print(f\"BLEU Score for Entity-Aware MT: {bleu_score['score']:.2f}\")\n",
    "    return bleu_score,sources,predictions,references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fae950f4-41e1-477a-80de-e5808cb9cc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Translations: 100%|█████████████████████████████████████████████████████| 1660/1660 [15:40<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Entity-Aware MT: 42.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score,sources,predictions,references = evaluate_test_data(test_data,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fd1cf2a3-f0dd-42d5-a3c2-bfc9a54fbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_test = os.path.join(os.getcwd(),r\"data\\train_data.json\")\n",
    "# test_data = load_preprocess_test(data_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "741f6f38-c767-48e4-89a9-3091059f9b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('De quelle civilisation le dieu Râ était-il le dieu du soleil ?',\n",
       " ['De quelle civilisation le dieu Râ était-il le dieu du soleil ?'],\n",
       " 'The God Ra, a Sun God, is from which civilization?')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions[10],references[10],sources[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4bba3-ae4d-4a16-a149-a6abed9ff265",
   "metadata": {},
   "source": [
    "### Loading the saved model and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "eca46708-4d27-4149-a24d-0bed2ed6f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.getcwd(),\"tf_base_finetuned\" )\n",
    "saved_tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "saved_model = T5ForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89afe1-c1c4-4902-8e14-fe03f3eca01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,sources,predictions,references = evaluate_test_data(test_data[:10],saved_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da25c1-ba7d-46ef-83cb-60a392366a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_data = [{\"src\": src, \"mt\": mt} for src, mt in zip(sources, predictions)]\n",
    "scores = comet_model.predict(comet_data, batch_size=8, gpus=1)\n",
    "print(\"System-level COMET score:\", scores[\"system_score\"])\n",
    "print(\"📊 Segment-level scores:\", scores[\"scores\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35042d8-9c9b-4dcb-9403-58a700007dc6",
   "metadata": {},
   "source": [
    "### Training without CustomLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6683ad87-4d8b-44c1-8a8f-236132f7bff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_16824\\1846769077.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29040' max='29040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29040/29040 4:06:39, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.058418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.036339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.017917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.012929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.009879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.007241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.005521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.004874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.003487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.002834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.002466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.002169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.000885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=29040, training_loss=0.026444886944618478, metrics={'train_runtime': 14799.9572, 'train_samples_per_second': 15.693, 'train_steps_per_second': 1.962, 'total_flos': 3.976043566989312e+16, 'train_loss': 0.026444886944618478, 'epoch': 30.0})"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "93154785-8087-4279-b3ae-c2ca3ef69a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Translations: 100%|█████████████████████████████████████████████████████| 1660/1660 [15:47<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Entity-Aware MT: 42.29\n"
     ]
    }
   ],
   "source": [
    "_,sources,predictions,references = evaluate_test_data(test_data,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd16a9-a5af-447f-8e6c-47944399884b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d021c7f1-c97f-41eb-ba53-543d746a0524",
   "metadata": {},
   "source": [
    "### Training for only EA-MT task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "af8fb3b3-9194-422e-9080-615d0b813803",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6a72362b-328a-401d-8d27-97a5a47e0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0ccafc45-81c5-401b-91e2-ddee7e07b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(),r\"data\\train_data.json\")\n",
    "train_data = load_preprocess_train(data_path,only_eamt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a60b90bb-4ca0-4004-8ff1-e1ce451386da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250482c59fb64486a40bdb8859b7bd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3871 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = train_data.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d2aaecdb-a14e-4f8a-9d9a-29a40c2ef9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_16824\\1846769077.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14520' max='14520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14520/14520 2:07:04, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>0.073314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.050919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.035841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>0.026873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.020288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.014458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.011597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.009079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.007692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.005967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.005138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.004325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.003352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.002899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.002099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.001768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.001423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.001042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14520, training_loss=0.0467270033972815, metrics={'train_runtime': 7625.3254, 'train_samples_per_second': 15.23, 'train_steps_per_second': 1.904, 'total_flos': 1.988021783494656e+16, 'train_loss': 0.0467270033972815, 'epoch': 30.0})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cf54a059-a1df-4528-b0ce-feb3db30cd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to D:\\Byom (Don't Delete)\\LRNLP-updated-clean-21-04\\tf_only_eamt\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(os.getcwd(),\"tf_only_eamt\")\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "92d0f998-745e-4339-9d03-3a0b2e4a53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_test = os.path.join(os.getcwd(),r\"data\\test_data.json\")\n",
    "test_data = load_preprocess_test(data_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "18843833-650b-42e3-9c88-75e22ff5396f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Translations: 100%|█████████████████████████████████████████████████████| 1660/1660 [16:49<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Entity-Aware MT: 33.76\n"
     ]
    }
   ],
   "source": [
    "_,sources,predictions,references = evaluate_test_data(test_data,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8939be-94e7-4329-8160-2b16aa8e03f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ccb2a-a55f-4f65-8e9c-3fa98bc53631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff23e867-18bc-4bf8-baa1-ecfecf412076",
   "metadata": {},
   "source": [
    "#### Testing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b54f055-6a58-4d1c-ae15-24ff3fc1e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset, Dataset\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe5c661-7222-4eb1-89aa-eb9ab81785a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_train(data_path,only_eamt=False):\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    formatted_data = []\n",
    "    for sample in data:\n",
    "        source_text = sample[\"source\"]\n",
    "        target_text = sample[\"target\"]\n",
    "        entities = sample.get(\"enriched_entities\", [])\n",
    "\n",
    "        entity_annotations = [f\"{ent['entity_name']['en']}\" for ent in entities]\n",
    "        entity_text = \", \".join(entity_annotations) if entity_annotations else \"None\"\n",
    "\n",
    "        if only_eamt != True:\n",
    "            formatted_data.append({\n",
    "                    \"task\": \"NER\",\n",
    "                    \"input\": f\"Recognize entities: {source_text}\",\n",
    "                    \"output\": entity_text\n",
    "                })\n",
    "        formatted_data.append({\n",
    "            \"task\": \"Entity-aware MT\",\n",
    "            \"input\": f\"Entity translate (EN→FR): {source_text}\",\n",
    "            \"output\": target_text\n",
    "        })\n",
    "    return Dataset.from_list(formatted_data)\n",
    "def load_preprocess_test(data_path):\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    formatted_data = []\n",
    "    for sample in data:\n",
    "        source_text = sample[\"source\"]\n",
    "        target_text = sample[\"target\"]\n",
    "        formatted_data.append({\n",
    "            \"task\": \"Entity-aware MT\",\n",
    "            \"input\": f\"Entity translate (EN→FR): {source_text}\",\n",
    "            \"output\": target_text\n",
    "        })\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb4d26c-3f33-4bd6-af03-7f6557b94105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_tester(model_src,output_dir,epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_src)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_src)\n",
    "    model = model.to(device)\n",
    "    data_path = os.path.join(os.getcwd(),r\"data\\train_data.json\")\n",
    "    train_data = load_preprocess_train(data_path)\n",
    "    def preprocess_function(samples):\n",
    "        inputs = tokenizer(samples[\"input\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "        targets = tokenizer(samples[\"output\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "        inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "        inputs = {key: torch.tensor(value).to(device) for key, value in inputs.items()}\n",
    "        return inputs    \n",
    "    tokenized_dataset = train_data.map(preprocess_function, batched=True)\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    output_dir = os.path.join(os.getcwd(),output_dir)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=3e-4,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=2,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset,\n",
    "        eval_dataset=tokenized_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    data_path_test = os.path.join(os.getcwd(),r\"data\\test_data.json\")\n",
    "    test_data = load_preprocess_test(data_path_test)\n",
    "    def evaluate_test_data(test_data,tokenizer):\n",
    "        bleu = evaluate.load(\"sacrebleu\")\n",
    "        sources,predictions, references = [],[],[]\n",
    "        for sample in tqdm(test_data, desc=\"Evaluating Translations\"):\n",
    "            input_text = sample[\"input\"]\n",
    "            sources.append(input_text[26:])\n",
    "            expected_output = sample[\"output\"]\n",
    "            inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            inputs = {k: v.to(model.device) for k, v in inputs.items()} \n",
    "            outputs = model.generate(**inputs)\n",
    "            decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            predictions.append(decoded_output)\n",
    "            references.append([expected_output])  \n",
    "        bleu_score = bleu.compute(predictions=predictions, references=references)\n",
    "        print(f\"BLEU Score for Entity-Aware MT: {bleu_score['score']:.2f}\")\n",
    "        return bleu_score,sources,predictions,references\n",
    "    bleu_score,sources,predictions,references = evaluate_test_data(test_data,tokenizer)\n",
    "    return bleu_score,sources,predictions,references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daa39fb8-2536-4bc7-81b8-1e54aae5baab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ef64150a1a4fb1bc0fc65c3a6b0d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_4768\\1929716031.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9680' max='9680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9680/9680 31:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.215900</td>\n",
       "      <td>0.214477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.146666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.116541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.099362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>0.087831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.079080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.121500</td>\n",
       "      <td>0.072148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.068098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.064946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.064129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Translations: 100%|█████████████████████████████████████████████████████| 1660/1660 [10:16<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Entity-Aware MT: 33.09\n"
     ]
    }
   ],
   "source": [
    "model2 = \"google/t5-v1_1-small\"\n",
    "bleu_score,sources,predictions,references = trainer_tester(model2,\"t5-small\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef5aeb6f-4ecc-47fb-9e82-7e36538e163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model2\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e9a25b3-d83f-401f-85a3-0e4020914fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9013b4f1b5a0402cb0c6be0efe1b5c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\CSE IIT BHILAI\\.cache\\huggingface\\hub\\models--google--t5-v1_1-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d91ebcd66b4741b593c6a4970bacc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d77ac1dfcda41e4aa0fb7c314e47d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576aeceb37e048f2b7351ef9339b02ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d20115a07b4f5f8ba03c1fe79ca457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46f9eeb04514760aebee5626749012c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2aeace2c447420182c1fbb3b19459b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_4768\\1929716031.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9680' max='9680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9680/9680 1:22:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.987000</td>\n",
       "      <td>0.305785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.240272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.119371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.077986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.058366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.044545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>0.036549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.030705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.027256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.025757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b377539923654194aae5d313179e5eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Translations: 100%|█████████████████████████████████████████████████████| 1660/1660 [15:49<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Entity-Aware MT: 36.91\n"
     ]
    }
   ],
   "source": [
    "model3 = \"google/t5-v1_1-base\"\n",
    "bleu_score,sources,predictions,references = trainer_tester(model3,\"t5-base\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0e19226-7cb9-4496-a2e1-08a9b71cba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model3\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75a1d6bd-7ae1-4462-ae1c-3ea3152422e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12dfcc3bb7c548b39aa2bf14fcb49cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\CSE IIT BHILAI\\.cache\\huggingface\\hub\\models--google--mt5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05efbc5ba4404220b942d7a6604877c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1ab0e1bce54ef183c9f94007179962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a19425fced24817b5fce3dd051540b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b453f815e914157a1dcf82b6f32f071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bab7e3854d046899c52ee1b9dafaff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7891cc263b348fbb2242bced995221a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_4768\\1929716031.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9680' max='9680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9680/9680 1:16:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.122700</td>\n",
       "      <td>0.715235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.598300</td>\n",
       "      <td>0.263588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.272100</td>\n",
       "      <td>0.143983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.105486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.087580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.076745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.067438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.062088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.059473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.057787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f7b308ad6c44958e55977ec944a884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Evaluating Translations: 100%|█████████████████████████████████████████████████████| 1660/1660 [12:51<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Entity-Aware MT: 33.50\n"
     ]
    }
   ],
   "source": [
    "model4 = \"google/mt5-small\"\n",
    "bleu_score,sources,predictions,references = trainer_tester(model4,\"mt5-small\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71bf7d42-209f-4ee6-8579-1d75499b9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model4\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "878d6a85-021d-4ead-994c-dd0328e48638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cda557f10984dedad49476ea551319d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\CSE IIT BHILAI\\.cache\\huggingface\\hub\\models--google--mt5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd90dcee8ee42adb4157cad357f17db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1f4f17327b4b78bfcad07da97c25cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8d97d788934f349394767958bc762c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7bfb8f022b482cb98111b83f3ea32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93254fb4961d4360854a4cc68b494ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baacc233839a4e609edb9be9c1574417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_4768\\1929716031.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bab7c989b8403f97f9f8999ce7cd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4840' max='4840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4840/4840 11:30:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.121500</td>\n",
       "      <td>0.109755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.055694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.039690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>0.030259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.027131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Evaluating Translations: 100%|█████████████████████████████████████████████████████| 1660/1660 [16:08<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Entity-Aware MT: 41.21\n"
     ]
    }
   ],
   "source": [
    "model5 = \"google/mt5-base\"\n",
    "bleu_score,sources,predictions,references = trainer_tester(model5,\"mt5-base\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3d69b9a-e9e7-48a7-babf-c64d7057ad58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model5\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model5' is not defined"
     ]
    }
   ],
   "source": [
    "del model5\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654b855d-590e-4336-91f4-0b115bba2187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18537b76ce5d42c29a2eaaed829fbf00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_5464\\592578065.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3872' max='3872' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3872/3872 7:10:49, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.039539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.021369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Translations: 100%|█████████████████████████████████████████████████████| 1660/1660 [28:57<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Entity-Aware MT: 43.15\n"
     ]
    }
   ],
   "source": [
    "model1 = \"google/flan-t5-large\"\n",
    "bleu_score,sources,predictions,references = trainer_tester(model1,\"flan-t5-large\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15718574-1c0c-4011-80ef-aeddcfecfeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c3ea5b-bead-4d2a-896e-add90447cc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d558c9f154a438c9882ef1722395dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\anaconda3\\envs\\Byom\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_11392\\592578065.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19360' max='19360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19360/19360 35:31:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.086700</td>\n",
       "      <td>0.044335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.025214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.015147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.009681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.006549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.004213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.001441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.000793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Translations: 100%|█████████████████████████████████████████████████████| 1660/1660 [28:07<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Entity-Aware MT: 43.13\n"
     ]
    }
   ],
   "source": [
    "model1 = \"google/flan-t5-large\"\n",
    "bleu_score,sources,predictions,references = trainer_tester(model1,\"flan-t5-large\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ffe776-6663-4d8b-8115-5e5d01399b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b977165-c837-4a05-93cc-eeebae698d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
